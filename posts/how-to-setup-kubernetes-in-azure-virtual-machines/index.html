<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>How to Setup Kubernetes in Azure Virtual Machines | Book of Daniel</title>
<meta name=keywords content><meta name=description content="Welcome to the hard way of installing Kubernetes in Azure Virtual Machines. The instructions will be moreover same for On-prem. For many developers, using managed Kubernetes services like GKE, EKS, or AKS can be convenient, but they often abstract away the intricate details of how a cluster operates under the hood.
Requirements

  
      
          NODES
          IP
          HOSTNAME
          MACHINE TYPE
          OPERATING SYSTEM
      
  
  
      
          master
          172.16.39.14
          k8s-master.local
          Standard B2ms
          Ubuntu 24.04
      
      
          k8s-worker1
          172.16.39.23
          k8s-worker1.local
          Standard B4ms
          Ubuntu 24.04
      
  


Provisioning the Servers in Azure
To provision two Linux virtual machines (VMs) in Azure with the specified details, you can use the Azure CLI (az) to achieve this. Here’s how you can provision both machines using az vm create commands."><meta name=author content="Dan"><link rel=canonical href=https://bookofdaniel.in/posts/how-to-setup-kubernetes-in-azure-virtual-machines/><meta name=google-site-verification content="G-VXV565Z72E"><link crossorigin=anonymous href=/assets/css/stylesheet.f4293b8f53210bcabd910256bfd1bad549ca35946bf52a51c2e8d0bbc7e42cc8.css integrity="sha256-9Ck7j1MhC8q9kQJWv9G61UnKNZRr9SpRwujQu8fkLMg=" rel="preload stylesheet" as=style><link rel=icon href=https://bookofdaniel.in/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://bookofdaniel.in/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://bookofdaniel.in/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://bookofdaniel.in/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://bookofdaniel.in/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://bookofdaniel.in/posts/how-to-setup-kubernetes-in-azure-virtual-machines/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href=https://fonts.cdnfonts.com/css/code-new-roman rel=stylesheet><link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@400;700&display=swap" rel=stylesheet><script async src="https://www.googletagmanager.com/gtag/js?id=G-VXV565Z72E"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-VXV565Z72E")}</script><meta property="og:title" content="How to Setup Kubernetes in Azure Virtual Machines"><meta property="og:description" content="Welcome to the hard way of installing Kubernetes in Azure Virtual Machines. The instructions will be moreover same for On-prem. For many developers, using managed Kubernetes services like GKE, EKS, or AKS can be convenient, but they often abstract away the intricate details of how a cluster operates under the hood.
Requirements

  
      
          NODES
          IP
          HOSTNAME
          MACHINE TYPE
          OPERATING SYSTEM
      
  
  
      
          master
          172.16.39.14
          k8s-master.local
          Standard B2ms
          Ubuntu 24.04
      
      
          k8s-worker1
          172.16.39.23
          k8s-worker1.local
          Standard B4ms
          Ubuntu 24.04
      
  


Provisioning the Servers in Azure
To provision two Linux virtual machines (VMs) in Azure with the specified details, you can use the Azure CLI (az) to achieve this. Here’s how you can provision both machines using az vm create commands."><meta property="og:type" content="article"><meta property="og:url" content="https://bookofdaniel.in/posts/how-to-setup-kubernetes-in-azure-virtual-machines/"><meta property="og:image" content="https://bookofdaniel.in/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-09-12T13:44:27+05:30"><meta property="article:modified_time" content="2024-09-12T13:44:27+05:30"><meta property="og:site_name" content="Book of Daniel"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://bookofdaniel.in/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="How to Setup Kubernetes in Azure Virtual Machines"><meta name=twitter:description content="Welcome to the hard way of installing Kubernetes in Azure Virtual Machines. The instructions will be moreover same for On-prem. For many developers, using managed Kubernetes services like GKE, EKS, or AKS can be convenient, but they often abstract away the intricate details of how a cluster operates under the hood.
Requirements

  
      
          NODES
          IP
          HOSTNAME
          MACHINE TYPE
          OPERATING SYSTEM
      
  
  
      
          master
          172.16.39.14
          k8s-master.local
          Standard B2ms
          Ubuntu 24.04
      
      
          k8s-worker1
          172.16.39.23
          k8s-worker1.local
          Standard B4ms
          Ubuntu 24.04
      
  


Provisioning the Servers in Azure
To provision two Linux virtual machines (VMs) in Azure with the specified details, you can use the Azure CLI (az) to achieve this. Here’s how you can provision both machines using az vm create commands."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://bookofdaniel.in/posts/"},{"@type":"ListItem","position":2,"name":"How to Setup Kubernetes in Azure Virtual Machines","item":"https://bookofdaniel.in/posts/how-to-setup-kubernetes-in-azure-virtual-machines/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"How to Setup Kubernetes in Azure Virtual Machines","name":"How to Setup Kubernetes in Azure Virtual Machines","description":"Welcome to the hard way of installing Kubernetes in Azure Virtual Machines. The instructions will be moreover same for On-prem. For many developers, using managed Kubernetes services like GKE, EKS, or AKS can be convenient, but they often abstract away the intricate details of how a cluster operates under the hood.\nRequirements NODES IP HOSTNAME MACHINE TYPE OPERATING SYSTEM master 172.16.39.14 k8s-master.local Standard B2ms Ubuntu 24.04 k8s-worker1 172.16.39.23 k8s-worker1.local Standard B4ms Ubuntu 24.04 Provisioning the Servers in Azure To provision two Linux virtual machines (VMs) in Azure with the specified details, you can use the Azure CLI (az) to achieve this. Here’s how you can provision both machines using az vm create commands.\n","keywords":[],"articleBody":"Welcome to the hard way of installing Kubernetes in Azure Virtual Machines. The instructions will be moreover same for On-prem. For many developers, using managed Kubernetes services like GKE, EKS, or AKS can be convenient, but they often abstract away the intricate details of how a cluster operates under the hood.\nRequirements NODES IP HOSTNAME MACHINE TYPE OPERATING SYSTEM master 172.16.39.14 k8s-master.local Standard B2ms Ubuntu 24.04 k8s-worker1 172.16.39.23 k8s-worker1.local Standard B4ms Ubuntu 24.04 Provisioning the Servers in Azure To provision two Linux virtual machines (VMs) in Azure with the specified details, you can use the Azure CLI (az) to achieve this. Here’s how you can provision both machines using az vm create commands.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 # 1. Set common variables RESOURCE_GROUP=\"k8s-cluster\" LOCATION=\"eastus\" MASTER_VM_NAME=\"k8s-master\" WORKER_VM_NAME=\"k8s-worker1\" MASTER_IP=\"172.16.39.14\" WORKER_IP=\"172.16.39.23\" VNET_NAME=\"k8s-vnet\" SUBNET_NAME=\"k8s-subnet\" MASTER_HOSTNAME=\"k8s-master.local\" WORKER_HOSTNAME=\"k8s-worker1.local\" # 2. Resource group creation az group create --name $RESOURCE_GROUP --location $LOCATION # 3. Create a virtual network (VNet) az network vnet create \\ --resource-group $RESOURCE_GROUP \\ --name $VNET_NAME \\ --address-prefix 172.16.0.0/16 \\ --subnet-name $SUBNET_NAME \\ --subnet-prefix 172.16.39.0/24 # 4. Create static IP addresses # Create public IPs az network public-ip create --resource-group $RESOURCE_GROUP --name masterPublicIP --allocation-method Static --sku Standard az network public-ip create --resource-group $RESOURCE_GROUP --name worker1PublicIP --allocation-method Static --sku Standard # Create NIC for the master node az network nic create \\ --resource-group $RESOURCE_GROUP \\ --name masterNIC \\ --vnet-name $VNET_NAME \\ --subnet $SUBNET_NAME \\ --private-ip-address $MASTER_IP \\ --public-ip-address masterPublicIP # Create NIC for the worker node az network nic create \\ --resource-group $RESOURCE_GROUP \\ --name worker1NIC \\ --vnet-name $VNET_NAME \\ --subnet $SUBNET_NAME \\ --private-ip-address $WORKER_IP \\ --public-ip-address worker1PublicIP # 5. Provision the master node az vm create \\ --resource-group $RESOURCE_GROUP \\ --name $MASTER_VM_NAME \\ --size Standard_B2ms \\ --nics masterNIC \\ --image Canonical:0001-com-ubuntu-server-jammy:24_04-lts:latest \\ --admin-username azureuser \\ --generate-ssh-keys \\ --custom-data cloud-init.yaml \\ --host-name $MASTER_HOSTNAME # 6. Provision the worker node az vm create \\ --resource-group $RESOURCE_GROUP \\ --name $WORKER_VM_NAME \\ --size Standard_B4ms \\ --nics worker1NIC \\ --image Canonical:0001-com-ubuntu-server-jammy:24_04-lts:latest \\ --admin-username azureuser \\ --generate-ssh-keys \\ --custom-data cloud-init.yaml \\ --host-name $WORKER_HOSTNAME # 7. Verification az vm list --resource-group $RESOURCE_GROUP -o table This will show you the VMs with their details. You should see k8s-master and k8s-worker1 with the correct IP addresses and machine types.\nSystem Preparation for Kubernetes Installation Before diving into the installation of Kubernetes, it’s essential to prepare your system for optimal performance and stability. This section outlines the necessary steps to get both the master and worker nodes ready for Kubernetes.\nℹ️ Execute the following commands on both master and worker nodes.\n1. Update the OS First, ensure your system is up-to-date by running the following commands to update and upgrade all installed packages:\n1 2 sudo apt update sudo apt upgrade -y After the upgrade completes, reboot the system to apply all changes:\n1 sudo reboot 2. Set Hostname Assign meaningful hostnames to both your master and worker nodes. This makes it easier to identify and manage the nodes in your cluster.\nMaster Node: 1 sudo hostnamectl set-hostname \"k8s-master.local\" Worker Node: 1 sudo hostnamectl set-hostname \"k8s-worker1.local\" Next, update the /etc/hosts file on both nodes to map the hostnames to their corresponding IP addresses. Add the following lines to the file:\n1 2 172.16.39.14 k8s-master.local 172.16.39.23 k8s-worker1.local 3. Disable Swap Kubernetes requires swap to be disabled to function properly. This is crucial because the Kubelet, the primary Kubernetes agent running on each node, does not handle memory swapping well. Enabling swap can lead to performance degradation and unpredictable behavior in your cluster.\nDisable swap immediately with the following commands:\n1 2 3 sudo swapoff -a sudo sed -i '/ swap / s/^/#/' /etc/fstab sudo mount -a By commenting out the swap entry in /etc/fstab, this ensures swap remains disabled after a reboot. Verify swap is disabled with:\n1 free -h The output should indicate that swap is set to 0:\n1 2 3 total used free shared buff/cache available Mem: 7.8Gi 1.4Gi 4.9Gi 5.0Mi 1.7Gi 6.3Gi Swap: 0B 0B 0B 4. Update Kernel and Configure Modules For Kubernetes to run efficiently, specific kernel modules and network parameters need to be configured.\nFirst, create a configuration file for kernel modules:\n1 2 3 4 sudo tee /etc/modules-load.d/containerd.conf \u003c","wordCount":"3361","inLanguage":"en","image":"https://bookofdaniel.in/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2024-09-12T13:44:27+05:30","dateModified":"2024-09-12T13:44:27+05:30","author":[{"@type":"Person","name":"Dan"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://bookofdaniel.in/posts/how-to-setup-kubernetes-in-azure-virtual-machines/"},"publisher":{"@type":"Organization","name":"Book of Daniel","logo":{"@type":"ImageObject","url":"https://bookofdaniel.in/%3Clink%20/%20abs%20url%3E"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://bookofdaniel.in/ accesskey=h title="Book of Daniel (Alt + H)">Book of Daniel</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://bookofdaniel.in/posts/ title=Blog><span>Blog</span></a></li><li><a href=https://bookofdaniel.in/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://bookofdaniel.in/>Home</a>&nbsp;»&nbsp;<a href=https://bookofdaniel.in/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">How to Setup Kubernetes in Azure Virtual Machines</h1><div class=post-meta><span title='2024-09-12 13:44:27 +0530 +0530'>September 12, 2024</span>&nbsp;·&nbsp;16 min&nbsp;·&nbsp;3361 words&nbsp;·&nbsp;Dan</div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#requirements aria-label=Requirements>Requirements</a></li><li><a href=#provisioning-the-servers-in-azure aria-label="Provisioning the Servers in Azure">Provisioning the Servers in Azure</a></li><li><a href=#system-preparation-for-kubernetes-installation aria-label="System Preparation for Kubernetes Installation">System Preparation for Kubernetes Installation</a><ul><li><a href=#1-update-the-os aria-label="1. Update the OS">1. Update the OS</a></li><li><a href=#2-set-hostname aria-label="2. Set Hostname">2. Set Hostname</a></li><li><a href=#3-disable-swap aria-label="3. Disable Swap">3. Disable Swap</a></li><li><a href=#4-update-kernel-and-configure-modules aria-label="4. Update Kernel and Configure Modules">4. Update Kernel and Configure Modules</a></li></ul></li><li><a href=#installing-containerd-runtime-on-all-nodes aria-label="Installing Containerd Runtime on All Nodes">Installing Containerd Runtime on All Nodes</a></li><li><a href=#installing-kubeadm-kubelet-and-kubectl aria-label="Installing Kubeadm, Kubelet, and Kubectl">Installing Kubeadm, Kubelet, and Kubectl</a><ul><li><a href=#1-update-package-index-and-install-dependencies aria-label="1. Update Package Index and Install Dependencies">1. Update Package Index and Install Dependencies</a></li><li><a href=#2-add-the-kubernetes-signing-key aria-label="2. Add the Kubernetes Signing Key">2. Add the Kubernetes Signing Key</a></li><li><a href=#3-add-the-kubernetes-v131-repository aria-label="3. Add the Kubernetes v1.31 Repository">3. Add the Kubernetes v1.31 Repository</a></li><li><a href=#4-install-kubelet-kubeadm-and-kubectl aria-label="4. Install Kubelet, Kubeadm, and Kubectl">4. Install Kubelet, Kubeadm, and Kubectl</a></li><li><a href=#5-enable-the-kubelet-service-optional aria-label="5. Enable the Kubelet Service (Optional)">5. Enable the Kubelet Service (Optional)</a></li></ul></li><li><a href=#initializing-the-kubernetes-cluster-with-kubeadm aria-label="Initializing the Kubernetes Cluster with Kubeadm">Initializing the Kubernetes Cluster with Kubeadm</a></li><li><a href=#adding-worker-nodes-to-the-kubernetes-cluster aria-label="Adding Worker Nodes to the Kubernetes Cluster">Adding Worker Nodes to the Kubernetes Cluster</a></li><li><a href=#installing-calico-v3281-pod-network-for-the-kubernetes-cluster aria-label="Installing Calico (v3.28.1) Pod Network for the Kubernetes Cluster">Installing Calico (v3.28.1) Pod Network for the Kubernetes Cluster</a><ul><li><a href=#1-download-the-calico-manifest-file aria-label="1. Download the Calico Manifest File">1. Download the Calico Manifest File</a></li><li><a href=#2-edit-the-calico-manifest-using-sed aria-label="2. Edit the Calico Manifest Using sed">2. Edit the Calico Manifest Using <code>sed</code></a></li><li><a href=#3-apply-the-calico-manifest aria-label="3. Apply the Calico Manifest">3. Apply the Calico Manifest</a></li></ul></li><li><a href=#verifying-the-k8s-installation aria-label="Verifying the K8s Installation">Verifying the K8s Installation</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>Welcome to the hard way of installing Kubernetes in Azure Virtual Machines. The instructions will be moreover same for On-prem. For many developers, using managed Kubernetes services like GKE, EKS, or AKS can be convenient, but they often abstract away the intricate details of how a cluster operates under the hood.</p><h1 id=requirements>Requirements<a hidden class=anchor aria-hidden=true href=#requirements>#</a></h1><table><thead><tr><th style=text-align:left>NODES</th><th style=text-align:left>IP</th><th style=text-align:left>HOSTNAME</th><th style=text-align:left>MACHINE TYPE</th><th style=text-align:left>OPERATING SYSTEM</th></tr></thead><tbody><tr><td style=text-align:left>master</td><td style=text-align:left>172.16.39.14</td><td style=text-align:left>k8s-master.local</td><td style=text-align:left>Standard B2ms</td><td style=text-align:left>Ubuntu 24.04</td></tr><tr><td style=text-align:left>k8s-worker1</td><td style=text-align:left>172.16.39.23</td><td style=text-align:left>k8s-worker1.local</td><td style=text-align:left>Standard B4ms</td><td style=text-align:left>Ubuntu 24.04</td></tr></tbody></table><hr><h1 id=provisioning-the-servers-in-azure>Provisioning the Servers in Azure<a hidden class=anchor aria-hidden=true href=#provisioning-the-servers-in-azure>#</a></h1><p>To provision two Linux virtual machines (VMs) in Azure with the specified details, you can use the Azure CLI (az) to achieve this. Here’s how you can provision both machines using az vm create commands.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 1. Set common variables</span>
</span></span><span class=line><span class=cl>    <span class=nv>RESOURCE_GROUP</span><span class=o>=</span><span class=s2>&#34;k8s-cluster&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>LOCATION</span><span class=o>=</span><span class=s2>&#34;eastus&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>MASTER_VM_NAME</span><span class=o>=</span><span class=s2>&#34;k8s-master&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>WORKER_VM_NAME</span><span class=o>=</span><span class=s2>&#34;k8s-worker1&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>MASTER_IP</span><span class=o>=</span><span class=s2>&#34;172.16.39.14&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>WORKER_IP</span><span class=o>=</span><span class=s2>&#34;172.16.39.23&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>VNET_NAME</span><span class=o>=</span><span class=s2>&#34;k8s-vnet&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>SUBNET_NAME</span><span class=o>=</span><span class=s2>&#34;k8s-subnet&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>MASTER_HOSTNAME</span><span class=o>=</span><span class=s2>&#34;k8s-master.local&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>WORKER_HOSTNAME</span><span class=o>=</span><span class=s2>&#34;k8s-worker1.local&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. Resource group creation</span>
</span></span><span class=line><span class=cl>    az group create --name <span class=nv>$RESOURCE_GROUP</span> --location <span class=nv>$LOCATION</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. Create a virtual network (VNet)</span>
</span></span><span class=line><span class=cl>    az network vnet create <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --resource-group <span class=nv>$RESOURCE_GROUP</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --name <span class=nv>$VNET_NAME</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --address-prefix 172.16.0.0/16 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --subnet-name <span class=nv>$SUBNET_NAME</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --subnet-prefix 172.16.39.0/24
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 4. Create static IP addresses</span>
</span></span><span class=line><span class=cl>    <span class=c1># Create public IPs</span>
</span></span><span class=line><span class=cl>    az network public-ip create --resource-group <span class=nv>$RESOURCE_GROUP</span> --name masterPublicIP --allocation-method Static --sku Standard
</span></span><span class=line><span class=cl>    az network public-ip create --resource-group <span class=nv>$RESOURCE_GROUP</span> --name worker1PublicIP --allocation-method Static --sku Standard
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Create NIC for the master node</span>
</span></span><span class=line><span class=cl>    az network nic create <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>        --resource-group <span class=nv>$RESOURCE_GROUP</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>        --name masterNIC <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>        --vnet-name <span class=nv>$VNET_NAME</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>        --subnet <span class=nv>$SUBNET_NAME</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>        --private-ip-address <span class=nv>$MASTER_IP</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>        --public-ip-address masterPublicIP
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Create NIC for the worker node</span>
</span></span><span class=line><span class=cl>    az network nic create <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>        --resource-group <span class=nv>$RESOURCE_GROUP</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>        --name worker1NIC <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>        --vnet-name <span class=nv>$VNET_NAME</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>        --subnet <span class=nv>$SUBNET_NAME</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>        --private-ip-address <span class=nv>$WORKER_IP</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>        --public-ip-address worker1PublicIP
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 5. Provision the master node</span>
</span></span><span class=line><span class=cl>    az vm create <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --resource-group <span class=nv>$RESOURCE_GROUP</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --name <span class=nv>$MASTER_VM_NAME</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --size Standard_B2ms <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --nics masterNIC <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --image Canonical:0001-com-ubuntu-server-jammy:24_04-lts:latest <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --admin-username azureuser <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --generate-ssh-keys <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --custom-data cloud-init.yaml <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --host-name <span class=nv>$MASTER_HOSTNAME</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 6. Provision the worker node</span>
</span></span><span class=line><span class=cl>    az vm create <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --resource-group <span class=nv>$RESOURCE_GROUP</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --name <span class=nv>$WORKER_VM_NAME</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --size Standard_B4ms <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --nics worker1NIC <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --image Canonical:0001-com-ubuntu-server-jammy:24_04-lts:latest <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --admin-username azureuser <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --generate-ssh-keys <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --custom-data cloud-init.yaml <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --host-name <span class=nv>$WORKER_HOSTNAME</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 7. Verification</span>
</span></span><span class=line><span class=cl>    az vm list --resource-group <span class=nv>$RESOURCE_GROUP</span> -o table
</span></span></code></pre></td></tr></table></div></div><p>This will show you the VMs with their details. You should see <code>k8s-master</code> and <code>k8s-worker1</code> with the correct IP addresses and machine types.</p><hr><h1 id=system-preparation-for-kubernetes-installation>System Preparation for Kubernetes Installation<a hidden class=anchor aria-hidden=true href=#system-preparation-for-kubernetes-installation>#</a></h1><p>Before diving into the installation of Kubernetes, it&rsquo;s essential to prepare your system for optimal performance and stability. This section outlines the necessary steps to get both the master and worker nodes ready for Kubernetes.</p><blockquote><p>ℹ️ Execute the following commands on both master and worker nodes.</p></blockquote><h2 id=1-update-the-os>1. Update the OS<a hidden class=anchor aria-hidden=true href=#1-update-the-os>#</a></h2><p>First, ensure your system is up-to-date by running the following commands to update and upgrade all installed packages:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo apt update
</span></span><span class=line><span class=cl>sudo apt upgrade -y
</span></span></code></pre></td></tr></table></div></div><p>After the upgrade completes, reboot the system to apply all changes:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo reboot
</span></span></code></pre></td></tr></table></div></div><h2 id=2-set-hostname>2. Set Hostname<a hidden class=anchor aria-hidden=true href=#2-set-hostname>#</a></h2><p>Assign meaningful hostnames to both your master and worker nodes. This makes it easier to identify and manage the nodes in your cluster.</p><ul><li><strong>Master Node</strong>:</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo hostnamectl set-hostname <span class=s2>&#34;k8s-master.local&#34;</span>
</span></span></code></pre></td></tr></table></div></div><ul><li><strong>Worker Node</strong>:</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo hostnamectl set-hostname <span class=s2>&#34;k8s-worker1.local&#34;</span>
</span></span></code></pre></td></tr></table></div></div><p>Next, update the <code>/etc/hosts</code> file on both nodes to map the hostnames to their corresponding IP addresses. Add the following lines to the file:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>172.16.39.14 k8s-master.local
</span></span><span class=line><span class=cl>172.16.39.23 k8s-worker1.local
</span></span></code></pre></td></tr></table></div></div><h2 id=3-disable-swap>3. Disable Swap<a hidden class=anchor aria-hidden=true href=#3-disable-swap>#</a></h2><p>Kubernetes requires swap to be disabled to function properly. This is crucial because the <strong>Kubelet</strong>, the primary Kubernetes agent running on each node, does not handle memory swapping well. Enabling swap can lead to performance degradation and unpredictable behavior in your cluster.</p><p>Disable swap immediately with the following commands:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo swapoff -a
</span></span><span class=line><span class=cl>sudo sed -i <span class=s1>&#39;/ swap / s/^/#/&#39;</span> /etc/fstab
</span></span><span class=line><span class=cl>sudo mount -a
</span></span></code></pre></td></tr></table></div></div><p>By commenting out the swap entry in <code>/etc/fstab</code>, this ensures swap remains disabled after a reboot. Verify swap is disabled with:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>free -h
</span></span></code></pre></td></tr></table></div></div><p>The output should indicate that swap is set to 0:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>               total        used        free      shared  buff/cache   available
</span></span><span class=line><span class=cl>Mem:           7.8Gi       1.4Gi       4.9Gi       5.0Mi       1.7Gi       6.3Gi
</span></span><span class=line><span class=cl>Swap:             0B          0B          0B
</span></span></code></pre></td></tr></table></div></div><h2 id=4-update-kernel-and-configure-modules>4. Update Kernel and Configure Modules<a hidden class=anchor aria-hidden=true href=#4-update-kernel-and-configure-modules>#</a></h2><p>For Kubernetes to run efficiently, specific kernel modules and network parameters need to be configured.</p><p>First, create a configuration file for kernel modules:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo tee /etc/modules-load.d/containerd.conf <span class=s>&lt;&lt;EOF
</span></span></span><span class=line><span class=cl><span class=s>overlay
</span></span></span><span class=line><span class=cl><span class=s>br_netfilter
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span></code></pre></td></tr></table></div></div><ul><li><code>overlay</code>: Used for overlay filesystems, which are essential for container storage.</li><li><code>br_netfilter</code>: Enables Kubernetes to manage network traffic between containers.</li></ul><p>Next, load the required kernel modules:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo modprobe overlay
</span></span><span class=line><span class=cl>sudo modprobe br_netfilter
</span></span></code></pre></td></tr></table></div></div><p>Set the necessary kernel parameters for Kubernetes by creating a configuration file:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo tee /etc/sysctl.d/kubernetes.conf <span class=s>&lt;&lt;EOF
</span></span></span><span class=line><span class=cl><span class=s>net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span class=line><span class=cl><span class=s>net.bridge.bridge-nf-call-iptables = 1
</span></span></span><span class=line><span class=cl><span class=s>net.ipv4.ip_forward = 1
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span></code></pre></td></tr></table></div></div><p>Finally, reload the sysctl configuration to apply the new parameters:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo sysctl --system
</span></span></code></pre></td></tr></table></div></div><p>These steps ensure your system is properly prepared for the Kubernetes installation, providing a stable foundation for the cluster to run efficiently.</p><hr><h1 id=installing-containerd-runtime-on-all-nodes>Installing Containerd Runtime on All Nodes<a hidden class=anchor aria-hidden=true href=#installing-containerd-runtime-on-all-nodes>#</a></h1><p>A critical component of any Kubernetes cluster is the <strong>container runtime</strong>, which is responsible for running containers on each node. <strong>Containerd</strong> is a lightweight and powerful runtime that provides essential container lifecycle management, including image transfer, storage, and execution. Originally developed as part of Docker, it is now a key part of the Cloud Native Computing Foundation (CNCF) and is favored for Kubernetes environments due to its simplicity and performance.</p><p>To install <strong>containerd</strong> on all nodes in your Kubernetes cluster, follow these steps:</p><p>First, ensure that the necessary packages and dependencies are installed:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo apt install -y curl gnupg2 software-properties-common apt-transport-https ca-certificates
</span></span></code></pre></td></tr></table></div></div><p>Add Docker’s official GPG key and Docker’s repository to your system:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg <span class=p>|</span> sudo gpg --dearmour -o /etc/apt/trusted.gpg.d/docker.gpg
</span></span><span class=line><span class=cl>sudo add-apt-repository <span class=s2>&#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu </span><span class=k>$(</span>lsb_release -cs<span class=k>)</span><span class=s2> stable&#34;</span>
</span></span></code></pre></td></tr></table></div></div><p>Update your package lists to include the newly added Docker repository, and install <strong>containerd</strong>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo apt update
</span></span><span class=line><span class=cl>sudo apt install -y containerd.io
</span></span></code></pre></td></tr></table></div></div><p>Once <strong>containerd</strong> is installed, you need to configure it to work with <strong>Kubernetes</strong>. Generate the default configuration file and enable <strong>SystemdCgroup</strong>, which ensures that <strong>containerd</strong> integrates smoothly with Kubernetes, particularly when using systemd for process management:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>containerd config default <span class=p>|</span> sudo tee /etc/containerd/config.toml &gt;/dev/null 2&gt;<span class=p>&amp;</span><span class=m>1</span>
</span></span><span class=line><span class=cl>sudo sed -i <span class=s1>&#39;s/SystemdCgroup = false/SystemdCgroup = true/g&#39;</span> /etc/containerd/config.toml
</span></span></code></pre></td></tr></table></div></div><p>Finally, restart and enable the <strong>containerd</strong> service so that it starts automatically on system boot:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo systemctl restart containerd
</span></span><span class=line><span class=cl>sudo systemctl <span class=nb>enable</span> containerd
</span></span></code></pre></td></tr></table></div></div><p>By following these steps, you’ll have a robust and efficient container runtime in place, ready for Kubernetes. Repeat this process on each node to ensure consistency across the cluster.</p><hr><h1 id=installing-kubeadm-kubelet-and-kubectl>Installing Kubeadm, Kubelet, and Kubectl<a hidden class=anchor aria-hidden=true href=#installing-kubeadm-kubelet-and-kubectl>#</a></h1><p>Now that your system is prepared, it&rsquo;s time to install the essential Kubernetes components on all of your machines: <strong>kubeadm</strong>, <strong>kubelet</strong>, and <strong>kubectl</strong>.</p><ul><li><strong>kubeadm</strong>: This tool helps bootstrap the Kubernetes cluster.</li><li><strong>kubelet</strong>: The agent that runs on all nodes in the cluster, responsible for running pods and containers.</li><li><strong>kubectl</strong>: A command-line utility that lets you interact with the Kubernetes cluster.</li></ul><p>It&rsquo;s important to note that <strong>kubeadm</strong> will not manage or install <strong>kubelet</strong> or <strong>kubectl</strong> for you, so you must ensure that all these tools are on the correct version. Mismatches between <strong>kubeadm</strong>, <strong>kubelet</strong>, and <strong>kubectl</strong> versions can result in instability. Kubernetes does allow a one-minor-version difference between the <strong>kubelet</strong> and the control plane, but the <strong>kubelet</strong> version should never exceed the API server version. For example, <strong>kubelet</strong> v1.7.0 can work with an API server running v1.8.0, but not the other way around.</p><blockquote><p>Additionally, as of <strong>September 13, 2023</strong>, Kubernetes has moved to a new package repository hosted at <strong>pkgs.k8s.io</strong>, which you must use to install any Kubernetes versions after v1.24. The legacy repositories (apt.kubernetes.io) are deprecated and may be removed without notice.</p></blockquote><p>Follow the steps below to install these packages for Kubernetes v1.31:</p><h2 id=1-update-package-index-and-install-dependencies>1. Update Package Index and Install Dependencies<a hidden class=anchor aria-hidden=true href=#1-update-package-index-and-install-dependencies>#</a></h2><p>Start by updating the system’s package index and installing the necessary dependencies:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo apt-get update
</span></span><span class=line><span class=cl>sudo apt-get install -y apt-transport-https ca-certificates curl gpg
</span></span></code></pre></td></tr></table></div></div><h2 id=2-add-the-kubernetes-signing-key>2. Add the Kubernetes Signing Key<a hidden class=anchor aria-hidden=true href=#2-add-the-kubernetes-signing-key>#</a></h2><p>Download the Kubernetes signing key for the package repositories. If the directory <code>/etc/apt/keyrings</code> doesn&rsquo;t exist, create it before running the following command:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.31/deb/Release.key <span class=p>|</span> sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
</span></span></code></pre></td></tr></table></div></div><p>This ensures that you are installing authentic Kubernetes packages.</p><h2 id=3-add-the-kubernetes-v131-repository>3. Add the Kubernetes v1.31 Repository<a hidden class=anchor aria-hidden=true href=#3-add-the-kubernetes-v131-repository>#</a></h2><p>Add the Kubernetes v1.31 repository to your system’s sources list. If you need a different version, modify the version number in the URL accordingly:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>echo</span> <span class=s1>&#39;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /&#39;</span> <span class=p>|</span> sudo tee /etc/apt/sources.list.d/kubernetes.list
</span></span></code></pre></td></tr></table></div></div><h2 id=4-install-kubelet-kubeadm-and-kubectl>4. Install Kubelet, Kubeadm, and Kubectl<a hidden class=anchor aria-hidden=true href=#4-install-kubelet-kubeadm-and-kubectl>#</a></h2><p>Once the repository is added, update your package list and install <strong>kubeadm</strong>, <strong>kubelet</strong>, and <strong>kubectl</strong>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo apt-get update
</span></span><span class=line><span class=cl>sudo apt-get install -y kubelet kubeadm kubectl
</span></span><span class=line><span class=cl>sudo apt-mark hold kubelet kubeadm kubectl
</span></span></code></pre></td></tr></table></div></div><p>Marking the packages with <code>apt-mark hold</code> ensures they won&rsquo;t be accidentally updated during system upgrades, which is important for maintaining version stability across your cluster.</p><h2 id=5-enable-the-kubelet-service-optional>5. Enable the Kubelet Service (Optional)<a hidden class=anchor aria-hidden=true href=#5-enable-the-kubelet-service-optional>#</a></h2><p>Before you bootstrap the Kubernetes cluster with <strong>kubeadm</strong>, you can enable the <strong>kubelet</strong> service to start automatically on boot:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo systemctl <span class=nb>enable</span> --now kubelet
</span></span></code></pre></td></tr></table></div></div><p>These steps install the core tools required for setting up and managing your Kubernetes cluster. Make sure to follow them carefully on both your master and worker nodes.</p><hr><p>Here’s the blog paragraph based on your snippet:</p><hr><h1 id=initializing-the-kubernetes-cluster-with-kubeadm>Initializing the Kubernetes Cluster with Kubeadm<a hidden class=anchor aria-hidden=true href=#initializing-the-kubernetes-cluster-with-kubeadm>#</a></h1><p>With <strong>kubeadm</strong>, <strong>kubelet</strong>, and <strong>kubectl</strong> installed on your master and worker nodes, it’s time to initialize the Kubernetes cluster.</p><blockquote><p>ℹ️ This step should only be executed on the master node, as it sets up the control plane that will manage the cluster.</p></blockquote><p>To begin, use the following command on your <strong>master node</strong> to initialize the cluster:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo kubeadm init <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --pod-network-cidr<span class=o>=</span>10.10.0.0/16 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --control-plane-endpoint<span class=o>=</span>k8s-master.local
</span></span></code></pre></td></tr></table></div></div><ul><li><strong>&ndash;pod-network-cidr=10.10.0.0/16</strong>: This specifies the CIDR range for the pod network. You can modify this value based on your network architecture.</li><li><strong>&ndash;control-plane-endpoint=k8s-master.local</strong>: This is the DNS or IP address of your control plane (master node). Ensure that the DNS or IP is resolvable by all worker nodes in your cluster.</li></ul><p>After running this command, kubeadm will perform the following tasks:</p><ol><li>Download and install the necessary control plane components such as <strong>etcd</strong>, <strong>kube-apiserver</strong>, <strong>kube-scheduler</strong>, and <strong>kube-controller-manager</strong>.</li><li>Set up your cluster according to the parameters provided.</li><li>Generate a join token that worker nodes can use to join the cluster.</li></ol><p>Once the initialization is complete, kubeadm will output instructions to finish setting up <strong>kubectl</strong> on the master node and provide the join command for your worker nodes.</p><p><strong>Notes:</strong></p><ul><li>The <code>--pod-network-cidr</code> value must align with the configuration of the pod network solution (e.g., Calico, Flannel) you plan to deploy.</li><li>Make sure that the control plane endpoint (<code>k8s-master.local</code>) is properly configured in your DNS or <code>/etc/hosts</code> file so that all nodes can resolve it.</li></ul><p>At this point, the control plane will be ready, and the next step will be to install a network add-on to allow pod-to-pod communication within the cluster.</p><p><strong>Output</strong>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span><span class=lnt>81
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=n>azureuser</span><span class=err>@</span><span class=n>k8s</span><span class=o>-</span><span class=n>master</span><span class=p>:</span><span class=o>~$</span> <span class=n>sudo</span> <span class=n>kubeadm</span> <span class=n>init</span> \
</span></span><span class=line><span class=cl>  <span class=o>--</span><span class=n>pod</span><span class=o>-</span><span class=n>network</span><span class=o>-</span><span class=n>cidr</span><span class=o>=</span><span class=mf>10.10</span><span class=o>.</span><span class=mf>0.0</span><span class=o>/</span><span class=mi>16</span> \
</span></span><span class=line><span class=cl>  <span class=o>--</span><span class=n>control</span><span class=o>-</span><span class=n>plane</span><span class=o>-</span><span class=n>endpoint</span><span class=o>=</span><span class=n>k8s</span><span class=o>-</span><span class=n>master</span><span class=o>.</span><span class=n>local</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>init</span><span class=p>]</span> <span class=n>Using</span> <span class=n>Kubernetes</span> <span class=n>version</span><span class=p>:</span> <span class=n>v1</span><span class=o>.</span><span class=mf>26.1</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>preflight</span><span class=p>]</span> <span class=n>Running</span> <span class=n>pre</span><span class=o>-</span><span class=n>flight</span> <span class=n>checks</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>preflight</span><span class=p>]</span> <span class=n>Pulling</span> <span class=n>images</span> <span class=n>required</span> <span class=k>for</span> <span class=n>setting</span> <span class=n>up</span> <span class=n>a</span> <span class=n>Kubernetes</span> <span class=n>cluster</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>preflight</span><span class=p>]</span> <span class=n>This</span> <span class=n>might</span> <span class=n>take</span> <span class=n>a</span> <span class=n>minute</span> <span class=ow>or</span> <span class=n>two</span><span class=p>,</span> <span class=n>depending</span> <span class=n>on</span> <span class=n>the</span> <span class=n>speed</span> <span class=n>of</span> <span class=n>your</span> <span class=n>internet</span> <span class=n>connection</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>preflight</span><span class=p>]</span> <span class=n>You</span> <span class=n>can</span> <span class=n>also</span> <span class=n>perform</span> <span class=n>this</span> <span class=n>action</span> <span class=ow>in</span> <span class=n>beforehand</span> <span class=n>using</span> <span class=s1>&#39;kubeadm config images pull&#39;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Using</span> <span class=n>certificateDir</span> <span class=n>folder</span> <span class=s2>&#34;/etc/kubernetes/pki&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;ca&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;apiserver&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>apiserver</span> <span class=n>serving</span> <span class=n>cert</span> <span class=n>is</span> <span class=n>signed</span> <span class=k>for</span> <span class=n>DNS</span> <span class=n>names</span> <span class=p>[</span><span class=n>k8s</span><span class=o>-</span><span class=n>master</span><span class=o>.</span><span class=n>local</span> <span class=n>kubernetes</span> <span class=n>kubernetes</span><span class=o>.</span><span class=n>default</span> <span class=n>kubernetes</span><span class=o>.</span><span class=n>default</span><span class=o>.</span><span class=n>svc</span> <span class=n>kubernetes</span><span class=o>.</span><span class=n>default</span><span class=o>.</span><span class=n>svc</span><span class=o>.</span><span class=n>cluster</span><span class=o>.</span><span class=n>local</span><span class=p>]</span> <span class=ow>and</span> <span class=n>IPs</span> <span class=p>[</span><span class=mf>10.96</span><span class=o>.</span><span class=mf>0.1</span> <span class=mf>192.168</span><span class=o>.</span><span class=mf>1.10</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;apiserver-kubelet-client&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;front-proxy-ca&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;front-proxy-client&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;etcd/ca&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;etcd/server&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>etcd</span><span class=o>/</span><span class=n>server</span> <span class=n>serving</span> <span class=n>cert</span> <span class=n>is</span> <span class=n>signed</span> <span class=k>for</span> <span class=n>DNS</span> <span class=n>names</span> <span class=p>[</span><span class=n>k8s</span><span class=o>-</span><span class=n>master</span><span class=o>.</span><span class=n>local</span> <span class=n>localhost</span><span class=p>]</span> <span class=ow>and</span> <span class=n>IPs</span> <span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>1.10</span> <span class=mf>127.0</span><span class=o>.</span><span class=mf>0.1</span> <span class=p>::</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;etcd/peer&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>etcd</span><span class=o>/</span><span class=n>peer</span> <span class=n>serving</span> <span class=n>cert</span> <span class=n>is</span> <span class=n>signed</span> <span class=k>for</span> <span class=n>DNS</span> <span class=n>names</span> <span class=p>[</span><span class=n>k8s</span><span class=o>-</span><span class=n>master</span><span class=o>.</span><span class=n>local</span> <span class=n>localhost</span><span class=p>]</span> <span class=ow>and</span> <span class=n>IPs</span> <span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>1.10</span> <span class=mf>127.0</span><span class=o>.</span><span class=mf>0.1</span> <span class=p>::</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;etcd/healthcheck-client&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;apiserver-etcd-client&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;sa&#34;</span> <span class=n>key</span> <span class=ow>and</span> <span class=n>public</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubeconfig</span><span class=p>]</span> <span class=n>Using</span> <span class=n>kubeconfig</span> <span class=n>folder</span> <span class=s2>&#34;/etc/kubernetes&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubeconfig</span><span class=p>]</span> <span class=n>Writing</span> <span class=s2>&#34;admin.conf&#34;</span> <span class=n>kubeconfig</span> <span class=n>file</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubeconfig</span><span class=p>]</span> <span class=n>Writing</span> <span class=s2>&#34;kubelet.conf&#34;</span> <span class=n>kubeconfig</span> <span class=n>file</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubeconfig</span><span class=p>]</span> <span class=n>Writing</span> <span class=s2>&#34;controller-manager.conf&#34;</span> <span class=n>kubeconfig</span> <span class=n>file</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubeconfig</span><span class=p>]</span> <span class=n>Writing</span> <span class=s2>&#34;scheduler.conf&#34;</span> <span class=n>kubeconfig</span> <span class=n>file</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubelet</span><span class=o>-</span><span class=n>start</span><span class=p>]</span> <span class=n>Writing</span> <span class=n>kubelet</span> <span class=n>environment</span> <span class=n>file</span> <span class=n>with</span> <span class=n>flags</span> <span class=n>to</span> <span class=n>file</span> <span class=s2>&#34;/var/lib/kubelet/kubeadm-flags.env&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubelet</span><span class=o>-</span><span class=n>start</span><span class=p>]</span> <span class=n>Writing</span> <span class=n>kubelet</span> <span class=n>configuration</span> <span class=n>to</span> <span class=n>file</span> <span class=s2>&#34;/var/lib/kubelet/config.yaml&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubelet</span><span class=o>-</span><span class=n>start</span><span class=p>]</span> <span class=n>Starting</span> <span class=n>the</span> <span class=n>kubelet</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>control</span><span class=o>-</span><span class=n>plane</span><span class=p>]</span> <span class=n>Using</span> <span class=n>manifest</span> <span class=n>folder</span> <span class=s2>&#34;/etc/kubernetes/manifests&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>control</span><span class=o>-</span><span class=n>plane</span><span class=p>]</span> <span class=n>Creating</span> <span class=k>static</span> <span class=n>Pod</span> <span class=n>manifest</span> <span class=k>for</span> <span class=s2>&#34;kube-apiserver&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>control</span><span class=o>-</span><span class=n>plane</span><span class=p>]</span> <span class=n>Creating</span> <span class=k>static</span> <span class=n>Pod</span> <span class=n>manifest</span> <span class=k>for</span> <span class=s2>&#34;kube-controller-manager&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>control</span><span class=o>-</span><span class=n>plane</span><span class=p>]</span> <span class=n>Creating</span> <span class=k>static</span> <span class=n>Pod</span> <span class=n>manifest</span> <span class=k>for</span> <span class=s2>&#34;kube-scheduler&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>etcd</span><span class=p>]</span> <span class=n>Creating</span> <span class=k>static</span> <span class=n>Pod</span> <span class=n>manifest</span> <span class=k>for</span> <span class=n>local</span> <span class=n>etcd</span> <span class=ow>in</span> <span class=s2>&#34;/etc/kubernetes/manifests&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>wait</span><span class=o>-</span><span class=n>control</span><span class=o>-</span><span class=n>plane</span><span class=p>]</span> <span class=n>Waiting</span> <span class=k>for</span> <span class=n>the</span> <span class=n>kubelet</span> <span class=n>to</span> <span class=n>boot</span> <span class=n>up</span> <span class=n>the</span> <span class=n>control</span> <span class=n>plane</span> <span class=n>as</span> <span class=k>static</span> <span class=n>Pods</span> <span class=n>from</span> <span class=n>directory</span> <span class=s2>&#34;/etc/kubernetes/manifests&#34;</span><span class=o>.</span> <span class=n>This</span> <span class=n>can</span> <span class=n>take</span> <span class=n>up</span> <span class=n>to</span> <span class=mi>4</span><span class=n>m0s</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>apiclient</span><span class=p>]</span> <span class=n>All</span> <span class=n>control</span> <span class=n>plane</span> <span class=n>components</span> <span class=n>are</span> <span class=n>healthy</span> <span class=n>after</span> <span class=mf>7.503422</span> <span class=n>seconds</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>upload</span><span class=o>-</span><span class=n>config</span><span class=p>]</span> <span class=n>Storing</span> <span class=n>the</span> <span class=n>configuration</span> <span class=n>used</span> <span class=ow>in</span> <span class=n>ConfigMap</span> <span class=s2>&#34;kubeadm-config&#34;</span> <span class=ow>in</span> <span class=n>the</span> <span class=s2>&#34;kube-system&#34;</span> <span class=n>Namespace</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubelet</span><span class=p>]</span> <span class=n>Creating</span> <span class=n>a</span> <span class=n>ConfigMap</span> <span class=s2>&#34;kubelet-config&#34;</span> <span class=ow>in</span> <span class=n>namespace</span> <span class=n>kube</span><span class=o>-</span><span class=n>system</span> <span class=n>with</span> <span class=n>the</span> <span class=n>configuration</span> <span class=k>for</span> <span class=n>the</span> <span class=n>kubelets</span> <span class=ow>in</span> <span class=n>the</span> <span class=n>cluster</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>upload</span><span class=o>-</span><span class=n>certs</span><span class=p>]</span> <span class=n>Skipping</span> <span class=n>phase</span><span class=o>.</span> <span class=n>Please</span> <span class=n>see</span> <span class=o>--</span><span class=n>upload</span><span class=o>-</span><span class=n>certs</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>mark</span><span class=o>-</span><span class=n>control</span><span class=o>-</span><span class=n>plane</span><span class=p>]</span> <span class=n>Marking</span> <span class=n>the</span> <span class=n>node</span> <span class=n>k8s</span><span class=o>-</span><span class=n>master</span><span class=o>.</span><span class=n>local</span> <span class=n>as</span> <span class=n>control</span><span class=o>-</span><span class=n>plane</span> <span class=n>by</span> <span class=n>adding</span> <span class=n>the</span> <span class=n>labels</span><span class=p>:</span> <span class=p>[</span><span class=n>node</span><span class=o>-</span><span class=n>role</span><span class=o>.</span><span class=n>kubernetes</span><span class=o>.</span><span class=n>io</span><span class=o>/</span><span class=n>control</span><span class=o>-</span><span class=n>plane</span> <span class=n>node</span><span class=o>.</span><span class=n>kubernetes</span><span class=o>.</span><span class=n>io</span><span class=o>/</span><span class=n>exclude</span><span class=o>-</span><span class=n>from</span><span class=o>-</span><span class=n>external</span><span class=o>-</span><span class=nb>load</span><span class=o>-</span><span class=n>balancers</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>mark</span><span class=o>-</span><span class=n>control</span><span class=o>-</span><span class=n>plane</span><span class=p>]</span> <span class=n>Marking</span> <span class=n>the</span> <span class=n>node</span> <span class=n>k8s</span><span class=o>-</span><span class=n>master</span><span class=o>.</span><span class=n>local</span> <span class=n>as</span> <span class=n>control</span><span class=o>-</span><span class=n>plane</span> <span class=n>by</span> <span class=n>adding</span> <span class=n>the</span> <span class=n>taints</span> <span class=p>[</span><span class=n>node</span><span class=o>-</span><span class=n>role</span><span class=o>.</span><span class=n>kubernetes</span><span class=o>.</span><span class=n>io</span><span class=o>/</span><span class=n>control</span><span class=o>-</span><span class=n>plane</span><span class=p>:</span><span class=n>NoSchedule</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>bootstrap</span><span class=o>-</span><span class=n>token</span><span class=p>]</span> <span class=n>Using</span> <span class=n>token</span><span class=p>:</span> <span class=n>daii9y</span><span class=o>.</span><span class=n>g4dq24u6irkz4pt0</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>bootstrap</span><span class=o>-</span><span class=n>token</span><span class=p>]</span> <span class=n>Configuring</span> <span class=n>bootstrap</span> <span class=n>tokens</span><span class=p>,</span> <span class=n>cluster</span><span class=o>-</span><span class=n>info</span> <span class=n>ConfigMap</span><span class=p>,</span><span class=n>RBAC</span> <span class=n>Roles</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>bootstrap</span><span class=o>-</span><span class=n>token</span><span class=p>]</span> <span class=n>Configured</span> <span class=n>RBAC</span> <span class=n>rules</span> <span class=n>to</span> <span class=n>allow</span> <span class=ne>Node</span> <span class=n>Bootstrap</span> <span class=n>tokens</span> <span class=n>to</span> <span class=n>get</span> <span class=n>nodes</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>bootstrap</span><span class=o>-</span><span class=n>token</span><span class=p>]</span> <span class=n>Configured</span> <span class=n>RBAC</span> <span class=n>rules</span> <span class=n>to</span> <span class=n>allow</span> <span class=ne>Node</span> <span class=n>Bootstrap</span> <span class=n>tokens</span> <span class=n>to</span> <span class=n>post</span> <span class=n>CSRs</span> <span class=ow>in</span> <span class=n>order</span> <span class=k>for</span> <span class=n>nodes</span> <span class=n>to</span> <span class=n>get</span> <span class=n>long</span> <span class=n>term</span> <span class=n>certificate</span> <span class=n>credentials</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>bootstrap</span><span class=o>-</span><span class=n>token</span><span class=p>]</span> <span class=n>Configured</span> <span class=n>RBAC</span> <span class=n>rules</span> <span class=n>to</span> <span class=n>allow</span> <span class=n>the</span> <span class=n>csrapprover</span> <span class=n>controller</span> <span class=n>automatically</span> <span class=n>approve</span> <span class=n>CSRs</span> <span class=n>from</span> <span class=n>a</span> <span class=ne>Node</span> <span class=n>Bootstrap</span> <span class=n>Token</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>bootstrap</span><span class=o>-</span><span class=n>token</span><span class=p>]</span> <span class=n>Configured</span> <span class=n>RBAC</span> <span class=n>rules</span> <span class=n>to</span> <span class=n>allow</span> <span class=n>certificate</span> <span class=n>rotation</span> <span class=k>for</span> <span class=n>all</span> <span class=n>node</span> <span class=n>client</span> <span class=n>certificates</span> <span class=ow>in</span> <span class=n>the</span> <span class=n>cluster</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>bootstrap</span><span class=o>-</span><span class=n>token</span><span class=p>]</span> <span class=n>Creating</span> <span class=n>the</span> <span class=s2>&#34;cluster-info&#34;</span> <span class=n>ConfigMap</span> <span class=ow>in</span> <span class=n>the</span> <span class=s2>&#34;kube-public&#34;</span> <span class=n>namespace</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubelet</span><span class=o>-</span><span class=n>finalize</span><span class=p>]</span> <span class=n>Updating</span> <span class=s2>&#34;/etc/kubernetes/kubelet.conf&#34;</span> <span class=n>to</span> <span class=n>point</span> <span class=n>to</span> <span class=n>a</span> <span class=n>rotatable</span> <span class=n>kubelet</span> <span class=n>client</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>addons</span><span class=p>]</span> <span class=n>Applied</span> <span class=n>essential</span> <span class=n>addon</span><span class=p>:</span> <span class=n>CoreDNS</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>addons</span><span class=p>]</span> <span class=n>Applied</span> <span class=n>essential</span> <span class=n>addon</span><span class=p>:</span> <span class=n>kube</span><span class=o>-</span><span class=n>proxy</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Your</span> <span class=n>Kubernetes</span> <span class=n>control</span><span class=o>-</span><span class=n>plane</span> <span class=n>has</span> <span class=n>initialized</span> <span class=n>successfully</span><span class=o>!</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>To</span> <span class=n>start</span> <span class=n>using</span> <span class=n>your</span> <span class=n>cluster</span><span class=p>,</span> <span class=n>you</span> <span class=n>need</span> <span class=n>to</span> <span class=n>run</span> <span class=n>the</span> <span class=n>following</span> <span class=n>as</span> <span class=n>a</span> <span class=n>regularuser</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>mkdir</span> <span class=o>-</span><span class=n>p</span> <span class=o>$</span><span class=n>HOME</span><span class=o>/.</span><span class=n>kube</span>
</span></span><span class=line><span class=cl>  <span class=n>sudo</span> <span class=n>cp</span> <span class=o>-</span><span class=n>i</span> <span class=o>/</span><span class=n>etc</span><span class=o>/</span><span class=n>kubernetes</span><span class=o>/</span><span class=n>admin</span><span class=o>.</span><span class=n>conf</span> <span class=o>$</span><span class=n>HOME</span><span class=o>/.</span><span class=n>kube</span><span class=o>/</span><span class=n>config</span>
</span></span><span class=line><span class=cl>  <span class=n>sudo</span> <span class=n>chown</span> <span class=o>$</span><span class=p>(</span><span class=n>id</span> <span class=o>-</span><span class=n>u</span><span class=p>):</span><span class=o>$</span><span class=p>(</span><span class=n>id</span> <span class=o>-</span><span class=n>g</span><span class=p>)</span> <span class=o>$</span><span class=n>HOME</span><span class=o>/.</span><span class=n>kube</span><span class=o>/</span><span class=n>config</span><span class=o>==</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Alternatively</span><span class=p>,</span> <span class=k>if</span> <span class=n>you</span> <span class=n>are</span> <span class=n>the</span> <span class=n>root</span> <span class=n>user</span><span class=p>,</span> <span class=n>you</span> <span class=n>can</span> <span class=n>run</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>export</span> <span class=n>KUBECONFIG</span><span class=o>=/</span><span class=n>etc</span><span class=o>/</span><span class=n>kubernetes</span><span class=o>/</span><span class=n>admin</span><span class=o>.</span><span class=n>conf</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>You</span> <span class=n>should</span> <span class=n>now</span> <span class=n>deploy</span> <span class=n>a</span> <span class=n>pod</span> <span class=n>network</span> <span class=n>to</span> <span class=n>the</span> <span class=n>cluster</span><span class=o>.</span>
</span></span><span class=line><span class=cl><span class=n>Run</span> <span class=s2>&#34;kubectl apply -f [podnetwork].yaml&#34;</span> <span class=n>with</span> <span class=n>one</span> <span class=n>of</span> <span class=n>the</span> <span class=n>options</span> <span class=n>listedat</span><span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>kubernetes</span><span class=o>.</span><span class=n>io</span><span class=o>/</span><span class=n>docs</span><span class=o>/</span><span class=n>concepts</span><span class=o>/</span><span class=n>cluster</span><span class=o>-</span><span class=n>administration</span><span class=o>/</span><span class=n>addons</span><span class=o>/</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>You</span> <span class=n>can</span> <span class=n>now</span> <span class=n>join</span> <span class=n>any</span> <span class=n>number</span> <span class=n>of</span> <span class=n>control</span><span class=o>-</span><span class=n>plane</span> <span class=n>nodes</span> <span class=n>by</span> <span class=n>copying</span> <span class=n>certificate</span> <span class=n>authorities</span>
</span></span><span class=line><span class=cl><span class=ow>and</span> <span class=n>service</span> <span class=n>account</span> <span class=n>keys</span> <span class=n>on</span> <span class=n>each</span> <span class=n>node</span> <span class=ow>and</span> <span class=n>then</span> <span class=n>running</span> <span class=n>the</span> <span class=n>following</span> <span class=n>asroot</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>kubeadm</span> <span class=n>join</span> <span class=n>k8s</span><span class=o>-</span><span class=n>master</span><span class=o>.</span><span class=n>local</span><span class=p>:</span><span class=mi>6443</span> <span class=o>--</span><span class=n>token</span> <span class=n>daii9y</span><span class=o>.</span><span class=n>g4dq24u6irkz4pt0</span> \
</span></span><span class=line><span class=cl>        <span class=o>--</span><span class=n>discovery</span><span class=o>-</span><span class=n>token</span><span class=o>-</span><span class=n>ca</span><span class=o>-</span><span class=n>cert</span><span class=o>-</span><span class=nb>hash</span> <span class=n>sha256</span><span class=p>:</span><span class=mi>58</span><span class=n>b9cc96ed57a5797fddea653756dbda830efbff55b720a10cffb3948d489148</span> \
</span></span><span class=line><span class=cl>        <span class=o>--</span><span class=n>control</span><span class=o>-</span><span class=n>plane</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Then</span> <span class=n>you</span> <span class=n>can</span> <span class=n>join</span> <span class=n>any</span> <span class=n>number</span> <span class=n>of</span> <span class=n>worker</span> <span class=n>nodes</span> <span class=n>by</span> <span class=n>running</span> <span class=n>the</span> <span class=n>following</span> <span class=n>on</span> <span class=n>each</span> <span class=n>as</span> <span class=n>root</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>kubeadm</span> <span class=n>join</span> <span class=n>k8s</span><span class=o>-</span><span class=n>master</span><span class=o>.</span><span class=n>local</span><span class=p>:</span><span class=mi>6443</span> <span class=o>--</span><span class=n>token</span> <span class=n>daii9y</span><span class=o>.</span><span class=n>g4dq24u6irkz4pt0</span> \
</span></span><span class=line><span class=cl>        <span class=o>--</span><span class=n>discovery</span><span class=o>-</span><span class=n>token</span><span class=o>-</span><span class=n>ca</span><span class=o>-</span><span class=n>cert</span><span class=o>-</span><span class=nb>hash</span> <span class=n>sha256</span><span class=p>:</span><span class=mi>58</span><span class=n>b9cc96ed57a5797fddea653756dbda830efbff55b720a10cffb3948d489148</span>
</span></span></code></pre></td></tr></table></div></div><blockquote><p>ℹ️ Now, As shown in the output execute below command in master node.</p></blockquote><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>mkdir -p <span class=nv>$HOME</span>/.kube
</span></span><span class=line><span class=cl>sudo cp -i /etc/kubernetes/admin.conf <span class=nv>$HOME</span>/.kube/config
</span></span><span class=line><span class=cl>sudo chown <span class=k>$(</span>id -u<span class=k>)</span>:<span class=k>$(</span>id -g<span class=k>)</span> <span class=nv>$HOME</span>/.kube/config
</span></span></code></pre></td></tr></table></div></div><p>Verify the cluster status:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl cluster-info
</span></span><span class=line><span class=cl>kubectl get nodes
</span></span></code></pre></td></tr></table></div></div><p><strong>Output</strong>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>azureuser@k8s-master:~$ kubectl cluster-info
</span></span><span class=line><span class=cl>Kubernetes control plane is running at https://k8s-master.local:6443
</span></span><span class=line><span class=cl>CoreDNS is running at https://k8s-master.local:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>To further debug and diagnose cluster problems, use <span class=s1>&#39;kubectl cluster-info dump&#39;</span>.
</span></span><span class=line><span class=cl>azureuser@k8s-master:~$ kubectl get nodes
</span></span><span class=line><span class=cl>NAME                    STATUS   ROLES           AGE    VERSION
</span></span><span class=line><span class=cl>k8s-master.local        Ready    control-plane   3d3h   v1.30.4
</span></span></code></pre></td></tr></table></div></div><p>It seems the control plane is running, we will proceed to add worker nodes to this cluster.</p><hr><h1 id=adding-worker-nodes-to-the-kubernetes-cluster>Adding Worker Nodes to the Kubernetes Cluster<a hidden class=anchor aria-hidden=true href=#adding-worker-nodes-to-the-kubernetes-cluster>#</a></h1><p>After initializing the Kubernetes cluster on the master node, it&rsquo;s time to add your worker nodes to the cluster. This will allow the control plane to distribute workloads across the nodes and manage them.</p><blockquote><p>ℹ️ To add a worker node, you need to execute the kubeadm join command in worker nodes.</p></blockquote><p>This command securely connects the worker node to the control plane. the command typically looks something like this:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubeadm join k8s-master.local:6443 --token daii9y.g4dq24u6irkz4pt0 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --discovery-token-ca-cert-hash sha256:58b9cc96ed57a5797fddea653756dbda830efbff55b720a10cffb3948d489148
</span></span></code></pre></td></tr></table></div></div><ul><li><strong>k8s-master.local:6443</strong>: This is the control plane endpoint (master node&rsquo;s address).</li><li><strong>&ndash;token</strong>: The token generated during the kubeadm init process, which allows the worker node to authenticate with the control plane.</li><li><strong>&ndash;discovery-token-ca-cert-hash</strong>: A hash that ensures the worker node securely discovers the control plane’s certificate authority.</li></ul><p>Once this command completes successfully, the worker node will be part of the Kubernetes cluster, ready to run workloads distributed by the control plane. You can verify that the node has joined the cluster by running the following command on the master node:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl get nodes
</span></span></code></pre></td></tr></table></div></div><p><strong>Output</strong>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>azureuser@k8s-master:~$ kubectl get nodes
</span></span><span class=line><span class=cl>NAME                    STATUS   ROLES           AGE    VERSION
</span></span><span class=line><span class=cl>k8s-master.local        Ready    control-plane   3d3h   v1.30.4
</span></span><span class=line><span class=cl>k8s-worker1.local       Ready    &lt;none&gt;          3d3h   v1.30.4
</span></span></code></pre></td></tr></table></div></div><p>This will list all nodes, including the newly added workers, along with their status in the cluster.</p><p>Repeat the process for each worker node to ensure that all machines are part of the cluster.</p><hr><p>Here’s the updated blog paragraph with the <code>sed</code> command for editing the Calico manifest:</p><hr><h1 id=installing-calico-v3281-pod-network-for-the-kubernetes-cluster>Installing Calico (v3.28.1) Pod Network for the Kubernetes Cluster<a hidden class=anchor aria-hidden=true href=#installing-calico-v3281-pod-network-for-the-kubernetes-cluster>#</a></h1><p>In order to allow communication between the pods in your cluster, you&rsquo;ll need to install a network add-on. One of the most popular options is <strong>Calico</strong>, which provides networking and network security capabilities for Kubernetes. Below, we&rsquo;ll walk through how to install <strong>Calico</strong> on your Kubernetes cluster.</p><blockquote><p>ℹ️ These commands should be run only on the <strong>master node</strong>.</p></blockquote><h2 id=1-download-the-calico-manifest-file>1. Download the Calico Manifest File<a hidden class=anchor aria-hidden=true href=#1-download-the-calico-manifest-file>#</a></h2><p>To begin, download the Calico manifest file, which is pre-configured for clusters with fewer than 50 nodes:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>curl https://raw.githubusercontent.com/projectcalico/calico/v3.28.1/manifests/calico.yaml -O
</span></span></code></pre></td></tr></table></div></div><p>This file contains all the necessary configuration to deploy Calico on your Kubernetes cluster.</p><h2 id=2-edit-the-calico-manifest-using-sed>2. Edit the Calico Manifest Using <code>sed</code><a hidden class=anchor aria-hidden=true href=#2-edit-the-calico-manifest-using-sed>#</a></h2><p>To streamline the process of modifying the <strong>CALICO_IPV4POOL_CIDR</strong> in the <strong>calico.yaml</strong> file, you can use the following <code>sed</code> command. This automatically updates the pod network CIDR without manually opening the file:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sed -i <span class=s1>&#39;s/value: &#34;192.168.0.0\/16&#34;/value: &#34;10.10.0.0\/16&#34;/&#39;</span> calico.yaml
</span></span></code></pre></td></tr></table></div></div><p>This command ensures that the pod network CIDR matches the one you specified during cluster initialization (<code>10.10.0.0/16</code>).</p><h2 id=3-apply-the-calico-manifest>3. Apply the Calico Manifest<a hidden class=anchor aria-hidden=true href=#3-apply-the-calico-manifest>#</a></h2><p>Once the manifest is updated, install Calico by applying the configuration using <strong>kubectl</strong>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl apply -f calico.yaml
</span></span></code></pre></td></tr></table></div></div><p>Calico will be deployed on your cluster, enabling pod-to-pod communication and enforcing network policies.</p><p><strong>Output</strong>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>azureuser@k8s-master:~$ kubectl apply -f calico.yaml
</span></span><span class=line><span class=cl>poddisruptionbudget.policy/calico-kube-controllers created
</span></span><span class=line><span class=cl>serviceaccount/calico-kube-controllers created
</span></span><span class=line><span class=cl>serviceaccount/calico-node created
</span></span><span class=line><span class=cl>configmap/calico-config created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/caliconodestatuses.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/ipreservations.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created
</span></span><span class=line><span class=cl>clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created
</span></span><span class=line><span class=cl>clusterrole.rbac.authorization.k8s.io/calico-node created
</span></span><span class=line><span class=cl>clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created
</span></span><span class=line><span class=cl>clusterrolebinding.rbac.authorization.k8s.io/calico-node created
</span></span><span class=line><span class=cl>daemonset.apps/calico-node created
</span></span><span class=line><span class=cl>deployment.apps/calico-kube-controllers created
</span></span></code></pre></td></tr></table></div></div><h1 id=verifying-the-k8s-installation>Verifying the K8s Installation<a hidden class=anchor aria-hidden=true href=#verifying-the-k8s-installation>#</a></h1><p>You can verify that Calico is running correctly by checking the status of the pods in the <code>kube-system</code> namespace:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl get pods -n kube-system
</span></span></code></pre></td></tr></table></div></div><p><strong>Output</strong>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>azureuser@k8s-master:~$ kubectl get pods -n kube-system
</span></span><span class=line><span class=cl>NAME                                           READY   STATUS    RESTARTS        AGE
</span></span><span class=line><span class=cl>calico-kube-controllers-77d59654f4-25crd       1/1     Running   <span class=m>5</span> <span class=o>(</span>3h59m ago<span class=o>)</span>   3d3h
</span></span><span class=line><span class=cl>calico-node-hqf82                              1/1     Running   <span class=m>2</span> <span class=o>(</span>3h59m ago<span class=o>)</span>   3d3h
</span></span><span class=line><span class=cl>calico-node-jxwbm                              1/1     Running   <span class=m>4</span> <span class=o>(</span>3h55m ago<span class=o>)</span>   3d3h
</span></span><span class=line><span class=cl>coredns-7db6d8ff4d-6f9cn                       1/1     Running   <span class=m>2</span> <span class=o>(</span>3h59m ago<span class=o>)</span>   3d4h
</span></span><span class=line><span class=cl>coredns-7db6d8ff4d-dnzq2                       1/1     Running   <span class=m>2</span> <span class=o>(</span>3h59m ago<span class=o>)</span>   3d4h
</span></span></code></pre></td></tr></table></div></div><p>You should see Calico components such as <code>calico-node</code> and <code>calico-kube-controllers</code> running successfully.</p><p>With Calico installed, your Kubernetes cluster is now fully networked, allowing pods to communicate across nodes as necessary. You can also configure Calico for advanced network security features if needed.</p><p>Now if we check the status of the nodes, the status will be Ready.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl get nodes
</span></span></code></pre></td></tr></table></div></div><p><strong>Output</strong>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>azureuser@k8s-master:~$ kubectl get nodes
</span></span><span class=line><span class=cl>NAME                    STATUS   ROLES           AGE    VERSION
</span></span><span class=line><span class=cl>k8s-master.local    Ready    control-plane   3d4h   v1.30.4
</span></span><span class=line><span class=cl>k8s-worker1.local   Ready    &lt;none&gt;          3d4h   v1.30.4
</span></span></code></pre></td></tr></table></div></div><hr><p>Congrats, if you reach till the end 😊. You are a soldier 🪖.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://bookofdaniel.in/posts/how-to-supercharge-your-focus-a-revolutionar-approach/><span class=title>« Prev</span><br><span>How to Supercharge Your Focus a Revolutionary Approach</span>
</a><a class=next href=https://bookofdaniel.in/posts/how-programmers-can-become-10x-more-effective/><span class=title>Next »</span><br><span>How Programmers Can Become 10X More Effective</span></a></nav></footer><script src=https://giscus.app/client.js data-repo=dannotes/bookofdaniel-comments data-repo-id=R_kgDOMwnsUw data-category=Comments data-category-id=DIC_kwDOMwnsU84CiaCW data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=dark data-lang=en crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2024 <a href=https://bookofdaniel.in/>Book of Daniel</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>