<!DOCTYPE html>
<html><head>
<title>How to Setup Kubernetes in Azure Virtual Machines</title>




<meta charset="utf-8">
<meta name="X-UA-Compatible" content="IE=edge">
<meta name="google-site-verification" content="">
<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
<meta content="telephone=no" name="format-detection">
<meta name="description" content="">
<meta name="renderer" content="webkit">
<meta name="theme-color" content="#ffffff">















  






      <script src="/js/toc.js"></script>
    
    <link type="text/css" rel="stylesheet" href="/vendor/css/bootstrap.min.css">

<link rel="stylesheet" href="/scss/dark-mode.min.ff0aac816f46e60f7fa3eff2233a3a7afab2864b4571de3a7bad7adaba84c3cb.css" integrity="sha256-/wqsgW9G5g9/o&#43;/yIzo6evqyhktFcd46e6162rqEw8s=" media="screen">


<link rel="stylesheet"
          href="https://fonts.googleapis.com/css?family=Material+Icons">



















</head>
<body>
    	<div id="app"><div class="single-column-drawer-container" id="drawer"
     v-bind:class="{ 'single-column-drawer-container-active': isDrawerOpen }">
    <div class="drawer-content">
        <div class="drawer-menu">
            
            
            
                
                
                
                    
                
                
                
                <a class="a-block drawer-menu-item active" href="/posts">
                    Archives
                </a>
                
            
            
            <div class="toc">


	<div class="toc-content">
	
		
		
		
		<center>- CATALOG -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#requirements" class="nav-requirements">
									Requirements
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#provisioning-the-servers-in-azure" class="nav-provisioning-the-servers-in-azure">
									Provisioning the Servers in Azure
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#system-preparation-for-kubernetes-installation" class="nav-system-preparation-for-kubernetes-installation">
									System Preparation for Kubernetes Installation
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#1-update-the-os" class="nav-1-update-the-os">
									1. Update the OS
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#2-set-hostname" class="nav-2-set-hostname">
									2. Set Hostname
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#3-disable-swap" class="nav-3-disable-swap">
									3. Disable Swap
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#4-update-kernel-and-configure-modules" class="nav-4-update-kernel-and-configure-modules">
									4. Update Kernel and Configure Modules
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#installing-containerd-runtime-on-all-nodes" class="nav-installing-containerd-runtime-on-all-nodes">
									Installing Containerd Runtime on All Nodes
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#installing-kubeadm-kubelet-and-kubectl" class="nav-installing-kubeadm-kubelet-and-kubectl">
									Installing Kubeadm, Kubelet, and Kubectl
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#1-update-package-index-and-install-dependencies" class="nav-1-update-package-index-and-install-dependencies">
									1. Update Package Index and Install Dependencies
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#2-add-the-kubernetes-signing-key" class="nav-2-add-the-kubernetes-signing-key">
									2. Add the Kubernetes Signing Key
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#3-add-the-kubernetes-v131-repository" class="nav-3-add-the-kubernetes-v131-repository">
									3. Add the Kubernetes v1.31 Repository
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#4-install-kubelet-kubeadm-and-kubectl" class="nav-4-install-kubelet-kubeadm-and-kubectl">
									4. Install Kubelet, Kubeadm, and Kubectl
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#5-enable-the-kubelet-service-optional" class="nav-5-enable-the-kubelet-service-optional">
									5. Enable the Kubelet Service (Optional)
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#initializing-the-kubernetes-cluster-with-kubeadm" class="nav-initializing-the-kubernetes-cluster-with-kubeadm">
									Initializing the Kubernetes Cluster with Kubeadm
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#adding-worker-nodes-to-the-kubernetes-cluster" class="nav-adding-worker-nodes-to-the-kubernetes-cluster">
									Adding Worker Nodes to the Kubernetes Cluster
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#installing-calico-v3281-pod-network-for-the-kubernetes-cluster" class="nav-installing-calico-v3281-pod-network-for-the-kubernetes-cluster">
									Installing Calico (v3.28.1) Pod Network for the Kubernetes Cluster
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#1-download-the-calico-manifest-file" class="nav-1-download-the-calico-manifest-file">
									1. Download the Calico Manifest File
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#2-edit-the-calico-manifest-using-sed" class="nav-2-edit-the-calico-manifest-using-sed">
									2. Edit the Calico Manifest Using sed
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#3-apply-the-calico-manifest" class="nav-3-apply-the-calico-manifest">
									3. Apply the Calico Manifest
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#verifying-the-k8s-installation" class="nav-verifying-the-k8s-installation">
									Verifying the K8s Installation
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
            
        </div>
    </div>
</div>
<transition name="fade">
    <div id="drawer-mask" v-bind:class="{ 'single-column-drawer-mask': mounted }" v-if="isDrawerOpen" v-on:click="toggleDrawer"></div>
</transition>
<nav id="navBar" class="navbar sticky-top navbar-light single-column-nav-container">
    <div id="navBackground" class="nav-background"></div>
    <div class="container container-narrow nav-content">
        <button id="nav_dropdown_btn" class="nav-dropdown-toggle" type="button" v-on:click="toggleDrawer">
            <i class="material-icons">
                menu
            </i>
        </button>
        <a id="navTitle" class="navbar-brand" href="https://bookofdaniel.in/">
            Book Of Daniel
        </a>
        
        <button type="button" class="nav-darkmode-toggle" id="darkModeToggleButton2">
            <i class="material-icons" id="darkModeToggleIcon2">
                dark_mode
            </i>
        </button>
        
    </div>
</nav>
<div class="single-column-header-container" id="pageHead"
     v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }">
    <a href="https://bookofdaniel.in/">
        <div class="single-column-header-title">Book Of Daniel</div>
        

    </a>
</div>

            <div id="content">
                <div id="streamContainer" class="stream-container">

    <div class="post-list-container post-list-container-shadow">
        <div class="post">
            
            
            

            <div class="post-head-wrapper-text-only"
                
            >
                <div class="post-title">
                    How to Setup Kubernetes in Azure Virtual Machines
                    
                    <div class="post-meta">
                        
                        <time itemprop="datePublished">
                            2024-09-06 12:07
                        </time>
                        

                        

                        
                        
                            <i class="material-icons" style="">schedule</i>
                            

                            
                            

                            
                            14 min
                            
                            4 s.
                        
                    </div>
                </div>
            </div>
            
            <div class="post-body-wrapper">
                
                <div class="post-body" v-pre>
                
                    <p>Welcome to the hard way of installing Kubernetes in Azure Virtual Machines. The instructions will be moreover same for On-prem. For many developers, using managed Kubernetes services like GKE, EKS, or AKS can be convenient, but they often abstract away the intricate details of how a cluster operates under the hood.</p>
<h1 id="requirements">Requirements</h1>
<table>
<thead>
<tr>
<th>NODES</th>
<th>IP</th>
<th>HOSTNAME</th>
<th>MACHINE TYPE</th>
<th>OPERATING SYSTEM</th>
</tr>
</thead>
<tbody>
<tr>
<td>master</td>
<td>172.16.39.14</td>
<td>k8s-master.local</td>
<td>Standard B2ms</td>
<td>Ubuntu 24.04</td>
</tr>
<tr>
<td>k8s-worker1</td>
<td>172.16.39.23</td>
<td>k8s-worker1.local</td>
<td>Standard B4ms</td>
<td>Ubuntu 24.04</td>
</tr>
</tbody>
</table>
<hr>
<h1 id="provisioning-the-servers-in-azure">Provisioning the Servers in Azure</h1>
<p>To provision two Linux virtual machines (VMs) in Azure with the specified details, you can use the Azure CLI (az) to achieve this. Here’s how you can provision both machines using az vm create commands.</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#8b949e;font-style:italic"># 1. Set common variables</span>
</span></span><span style="display:flex;"><span>    <span style="color:#79c0ff">RESOURCE_GROUP</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;k8s-cluster&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#79c0ff">LOCATION</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;eastus&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#79c0ff">MASTER_VM_NAME</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;k8s-master&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#79c0ff">WORKER_VM_NAME</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;k8s-worker1&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#79c0ff">MASTER_IP</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;172.16.39.14&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#79c0ff">WORKER_IP</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;172.16.39.23&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#79c0ff">VNET_NAME</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;k8s-vnet&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#79c0ff">SUBNET_NAME</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;k8s-subnet&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#79c0ff">MASTER_HOSTNAME</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;k8s-master.local&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#79c0ff">WORKER_HOSTNAME</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;k8s-worker1.local&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b949e;font-style:italic"># 2. Resource group creation</span>
</span></span><span style="display:flex;"><span>    az group create --name <span style="color:#79c0ff">$RESOURCE_GROUP</span> --location <span style="color:#79c0ff">$LOCATION</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b949e;font-style:italic"># 3. Create a virtual network (VNet)</span>
</span></span><span style="display:flex;"><span>    az network vnet create <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --resource-group <span style="color:#79c0ff">$RESOURCE_GROUP</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --name <span style="color:#79c0ff">$VNET_NAME</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --address-prefix 172.16.0.0/16 <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --subnet-name <span style="color:#79c0ff">$SUBNET_NAME</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --subnet-prefix 172.16.39.0/24
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b949e;font-style:italic"># 4. Create static IP addresses</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b949e;font-style:italic"># Create public IPs</span>
</span></span><span style="display:flex;"><span>    az network public-ip create --resource-group <span style="color:#79c0ff">$RESOURCE_GROUP</span> --name masterPublicIP --allocation-method Static --sku Standard
</span></span><span style="display:flex;"><span>    az network public-ip create --resource-group <span style="color:#79c0ff">$RESOURCE_GROUP</span> --name worker1PublicIP --allocation-method Static --sku Standard
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b949e;font-style:italic"># Create NIC for the master node</span>
</span></span><span style="display:flex;"><span>    az network nic create <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>        --resource-group <span style="color:#79c0ff">$RESOURCE_GROUP</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>        --name masterNIC <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>        --vnet-name <span style="color:#79c0ff">$VNET_NAME</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>        --subnet <span style="color:#79c0ff">$SUBNET_NAME</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>        --private-ip-address <span style="color:#79c0ff">$MASTER_IP</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>        --public-ip-address masterPublicIP
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b949e;font-style:italic"># Create NIC for the worker node</span>
</span></span><span style="display:flex;"><span>    az network nic create <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>        --resource-group <span style="color:#79c0ff">$RESOURCE_GROUP</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>        --name worker1NIC <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>        --vnet-name <span style="color:#79c0ff">$VNET_NAME</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>        --subnet <span style="color:#79c0ff">$SUBNET_NAME</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>        --private-ip-address <span style="color:#79c0ff">$WORKER_IP</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>        --public-ip-address worker1PublicIP
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b949e;font-style:italic"># 5. Provision the master node</span>
</span></span><span style="display:flex;"><span>    az vm create <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --resource-group <span style="color:#79c0ff">$RESOURCE_GROUP</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --name <span style="color:#79c0ff">$MASTER_VM_NAME</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --size Standard_B2ms <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --nics masterNIC <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --image Canonical:0001-com-ubuntu-server-jammy:24_04-lts:latest <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --admin-username azureuser <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --generate-ssh-keys <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --custom-data cloud-init.yaml <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --host-name <span style="color:#79c0ff">$MASTER_HOSTNAME</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b949e;font-style:italic"># 6. Provision the worker node</span>
</span></span><span style="display:flex;"><span>    az vm create <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --resource-group <span style="color:#79c0ff">$RESOURCE_GROUP</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --name <span style="color:#79c0ff">$WORKER_VM_NAME</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --size Standard_B4ms <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --nics worker1NIC <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --image Canonical:0001-com-ubuntu-server-jammy:24_04-lts:latest <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --admin-username azureuser <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --generate-ssh-keys <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --custom-data cloud-init.yaml <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    --host-name <span style="color:#79c0ff">$WORKER_HOSTNAME</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b949e;font-style:italic"># 7. Verification</span>
</span></span><span style="display:flex;"><span>    az vm list --resource-group <span style="color:#79c0ff">$RESOURCE_GROUP</span> -o table
</span></span></code></pre></div><p>This will show you the VMs with their details. You should see <code>k8s-master</code> and <code>k8s-worker1</code> with the correct IP addresses and machine types.</p>
<hr>
<h1 id="system-preparation-for-kubernetes-installation">System Preparation for Kubernetes Installation</h1>
<p>Before diving into the installation of Kubernetes, it&rsquo;s essential to prepare your system for optimal performance and stability. This section outlines the necessary steps to get both the master and worker nodes ready for Kubernetes.</p>
<blockquote>
<p>ℹ️ Execute the following commands on both master and worker nodes.</p>
</blockquote>
<h2 id="1-update-the-os">1. Update the OS</h2>
<p>First, ensure your system is up-to-date by running the following commands to update and upgrade all installed packages:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo apt update
</span></span><span style="display:flex;"><span>sudo apt upgrade -y
</span></span></code></pre></div><p>After the upgrade completes, reboot the system to apply all changes:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo reboot
</span></span></code></pre></div><h2 id="2-set-hostname">2. Set Hostname</h2>
<p>Assign meaningful hostnames to both your master and worker nodes. This makes it easier to identify and manage the nodes in your cluster.</p>
<ul>
<li><strong>Master Node</strong>:</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo hostnamectl set-hostname <span style="color:#a5d6ff">&#34;k8s-master.local&#34;</span>
</span></span></code></pre></div><ul>
<li><strong>Worker Node</strong>:</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo hostnamectl set-hostname <span style="color:#a5d6ff">&#34;k8s-worker1.local&#34;</span>
</span></span></code></pre></div><p>Next, update the <code>/etc/hosts</code> file on both nodes to map the hostnames to their corresponding IP addresses. Add the following lines to the file:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>172.16.39.14 k8s-master.local
</span></span><span style="display:flex;"><span>172.16.39.23 k8s-worker1.local
</span></span></code></pre></div><h2 id="3-disable-swap">3. Disable Swap</h2>
<p>Kubernetes requires swap to be disabled to function properly. This is crucial because the <strong>Kubelet</strong>, the primary Kubernetes agent running on each node, does not handle memory swapping well. Enabling swap can lead to performance degradation and unpredictable behavior in your cluster.</p>
<p>Disable swap immediately with the following commands:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo swapoff -a
</span></span><span style="display:flex;"><span>sudo sed -i <span style="color:#a5d6ff">&#39;/ swap / s/^/#/&#39;</span> /etc/fstab
</span></span><span style="display:flex;"><span>sudo mount -a
</span></span></code></pre></div><p>By commenting out the swap entry in <code>/etc/fstab</code>, this ensures swap remains disabled after a reboot. Verify swap is disabled with:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>free -h
</span></span></code></pre></div><p>The output should indicate that swap is set to 0:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>               total        used        free      shared  buff/cache   available
</span></span><span style="display:flex;"><span>Mem:           7.8Gi       1.4Gi       4.9Gi       5.0Mi       1.7Gi       6.3Gi
</span></span><span style="display:flex;"><span>Swap:             0B          0B          0B
</span></span></code></pre></div><h2 id="4-update-kernel-and-configure-modules">4. Update Kernel and Configure Modules</h2>
<p>For Kubernetes to run efficiently, specific kernel modules and network parameters need to be configured.</p>
<p>First, create a configuration file for kernel modules:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo tee /etc/modules-load.d/containerd.conf <span style="color:#a5d6ff">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#a5d6ff">overlay
</span></span></span><span style="display:flex;"><span><span style="color:#a5d6ff">br_netfilter
</span></span></span><span style="display:flex;"><span><span style="color:#a5d6ff">EOF</span>
</span></span></code></pre></div><ul>
<li><code>overlay</code>: Used for overlay filesystems, which are essential for container storage.</li>
<li><code>br_netfilter</code>: Enables Kubernetes to manage network traffic between containers.</li>
</ul>
<p>Next, load the required kernel modules:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo modprobe overlay
</span></span><span style="display:flex;"><span>sudo modprobe br_netfilter
</span></span></code></pre></div><p>Set the necessary kernel parameters for Kubernetes by creating a configuration file:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo tee /etc/sysctl.d/kubernetes.conf <span style="color:#a5d6ff">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#a5d6ff">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#a5d6ff">net.bridge.bridge-nf-call-iptables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#a5d6ff">net.ipv4.ip_forward = 1
</span></span></span><span style="display:flex;"><span><span style="color:#a5d6ff">EOF</span>
</span></span></code></pre></div><p>Finally, reload the sysctl configuration to apply the new parameters:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo sysctl --system
</span></span></code></pre></div><p>These steps ensure your system is properly prepared for the Kubernetes installation, providing a stable foundation for the cluster to run efficiently.</p>
<hr>
<h1 id="installing-containerd-runtime-on-all-nodes">Installing Containerd Runtime on All Nodes</h1>
<p>A critical component of any Kubernetes cluster is the <strong>container runtime</strong>, which is responsible for running containers on each node. <strong>Containerd</strong> is a lightweight and powerful runtime that provides essential container lifecycle management, including image transfer, storage, and execution. Originally developed as part of Docker, it is now a key part of the Cloud Native Computing Foundation (CNCF) and is favored for Kubernetes environments due to its simplicity and performance.</p>
<p>To install <strong>containerd</strong> on all nodes in your Kubernetes cluster, follow these steps:</p>
<p>First, ensure that the necessary packages and dependencies are installed:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo apt install -y curl gnupg2 software-properties-common apt-transport-https ca-certificates
</span></span></code></pre></div><p>Add Docker’s official GPG key and Docker’s repository to your system:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmour -o /etc/apt/trusted.gpg.d/docker.gpg
</span></span><span style="display:flex;"><span>sudo add-apt-repository <span style="color:#a5d6ff">&#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu </span><span style="color:#ff7b72">$(</span>lsb_release -cs<span style="color:#ff7b72">)</span><span style="color:#a5d6ff"> stable&#34;</span>
</span></span></code></pre></div><p>Update your package lists to include the newly added Docker repository, and install <strong>containerd</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo apt update
</span></span><span style="display:flex;"><span>sudo apt install -y containerd.io
</span></span></code></pre></div><p>Once <strong>containerd</strong> is installed, you need to configure it to work with <strong>Kubernetes</strong>. Generate the default configuration file and enable <strong>SystemdCgroup</strong>, which ensures that <strong>containerd</strong> integrates smoothly with Kubernetes, particularly when using systemd for process management:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>containerd config default | sudo tee /etc/containerd/config.toml &gt;/dev/null 2&gt;&amp;<span style="color:#a5d6ff">1</span>
</span></span><span style="display:flex;"><span>sudo sed -i <span style="color:#a5d6ff">&#39;s/SystemdCgroup = false/SystemdCgroup = true/g&#39;</span> /etc/containerd/config.toml
</span></span></code></pre></div><p>Finally, restart and enable the <strong>containerd</strong> service so that it starts automatically on system boot:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl restart containerd
</span></span><span style="display:flex;"><span>sudo systemctl enable containerd
</span></span></code></pre></div><p>By following these steps, you’ll have a robust and efficient container runtime in place, ready for Kubernetes. Repeat this process on each node to ensure consistency across the cluster.</p>
<hr>
<h1 id="installing-kubeadm-kubelet-and-kubectl">Installing Kubeadm, Kubelet, and Kubectl</h1>
<p>Now that your system is prepared, it&rsquo;s time to install the essential Kubernetes components on all of your machines: <strong>kubeadm</strong>, <strong>kubelet</strong>, and <strong>kubectl</strong>.</p>
<ul>
<li><strong>kubeadm</strong>: This tool helps bootstrap the Kubernetes cluster.</li>
<li><strong>kubelet</strong>: The agent that runs on all nodes in the cluster, responsible for running pods and containers.</li>
<li><strong>kubectl</strong>: A command-line utility that lets you interact with the Kubernetes cluster.</li>
</ul>
<p>It&rsquo;s important to note that <strong>kubeadm</strong> will not manage or install <strong>kubelet</strong> or <strong>kubectl</strong> for you, so you must ensure that all these tools are on the correct version. Mismatches between <strong>kubeadm</strong>, <strong>kubelet</strong>, and <strong>kubectl</strong> versions can result in instability. Kubernetes does allow a one-minor-version difference between the <strong>kubelet</strong> and the control plane, but the <strong>kubelet</strong> version should never exceed the API server version. For example, <strong>kubelet</strong> v1.7.0 can work with an API server running v1.8.0, but not the other way around.</p>
<blockquote>
<p>Additionally, as of <strong>September 13, 2023</strong>, Kubernetes has moved to a new package repository hosted at <strong>pkgs.k8s.io</strong>, which you must use to install any Kubernetes versions after v1.24. The legacy repositories (apt.kubernetes.io) are deprecated and may be removed without notice.</p>
</blockquote>
<p>Follow the steps below to install these packages for Kubernetes v1.31:</p>
<h2 id="1-update-package-index-and-install-dependencies">1. Update Package Index and Install Dependencies</h2>
<p>Start by updating the system’s package index and installing the necessary dependencies:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo apt-get update
</span></span><span style="display:flex;"><span>sudo apt-get install -y apt-transport-https ca-certificates curl gpg
</span></span></code></pre></div><h2 id="2-add-the-kubernetes-signing-key">2. Add the Kubernetes Signing Key</h2>
<p>Download the Kubernetes signing key for the package repositories. If the directory <code>/etc/apt/keyrings</code> doesn&rsquo;t exist, create it before running the following command:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.31/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
</span></span></code></pre></div><p>This ensures that you are installing authentic Kubernetes packages.</p>
<h2 id="3-add-the-kubernetes-v131-repository">3. Add the Kubernetes v1.31 Repository</h2>
<p>Add the Kubernetes v1.31 repository to your system’s sources list. If you need a different version, modify the version number in the URL accordingly:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>echo <span style="color:#a5d6ff">&#39;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /&#39;</span> | sudo tee /etc/apt/sources.list.d/kubernetes.list
</span></span></code></pre></div><h2 id="4-install-kubelet-kubeadm-and-kubectl">4. Install Kubelet, Kubeadm, and Kubectl</h2>
<p>Once the repository is added, update your package list and install <strong>kubeadm</strong>, <strong>kubelet</strong>, and <strong>kubectl</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo apt-get update
</span></span><span style="display:flex;"><span>sudo apt-get install -y kubelet kubeadm kubectl
</span></span><span style="display:flex;"><span>sudo apt-mark hold kubelet kubeadm kubectl
</span></span></code></pre></div><p>Marking the packages with <code>apt-mark hold</code> ensures they won&rsquo;t be accidentally updated during system upgrades, which is important for maintaining version stability across your cluster.</p>
<h2 id="5-enable-the-kubelet-service-optional">5. Enable the Kubelet Service (Optional)</h2>
<p>Before you bootstrap the Kubernetes cluster with <strong>kubeadm</strong>, you can enable the <strong>kubelet</strong> service to start automatically on boot:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl enable --now kubelet
</span></span></code></pre></div><p>These steps install the core tools required for setting up and managing your Kubernetes cluster. Make sure to follow them carefully on both your master and worker nodes.</p>
<hr>
<p>Here’s the blog paragraph based on your snippet:</p>
<hr>
<h1 id="initializing-the-kubernetes-cluster-with-kubeadm">Initializing the Kubernetes Cluster with Kubeadm</h1>
<p>With <strong>kubeadm</strong>, <strong>kubelet</strong>, and <strong>kubectl</strong> installed on your master and worker nodes, it’s time to initialize the Kubernetes cluster.</p>
<blockquote>
<p>ℹ️ This step should only be executed on the master node, as it sets up the control plane that will manage the cluster.</p>
</blockquote>
<p>To begin, use the following command on your <strong>master node</strong> to initialize the cluster:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo kubeadm init <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>  --pod-network-cidr<span style="color:#ff7b72;font-weight:bold">=</span>10.10.0.0/16 <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>  --control-plane-endpoint<span style="color:#ff7b72;font-weight:bold">=</span>k8s-master.local
</span></span></code></pre></div><ul>
<li><strong>&ndash;pod-network-cidr=10.10.0.0/16</strong>: This specifies the CIDR range for the pod network. You can modify this value based on your network architecture.</li>
<li><strong>&ndash;control-plane-endpoint=k8s-master.local</strong>: This is the DNS or IP address of your control plane (master node). Ensure that the DNS or IP is resolvable by all worker nodes in your cluster.</li>
</ul>
<p>After running this command, kubeadm will perform the following tasks:</p>
<ol>
<li>Download and install the necessary control plane components such as <strong>etcd</strong>, <strong>kube-apiserver</strong>, <strong>kube-scheduler</strong>, and <strong>kube-controller-manager</strong>.</li>
<li>Set up your cluster according to the parameters provided.</li>
<li>Generate a join token that worker nodes can use to join the cluster.</li>
</ol>
<p>Once the initialization is complete, kubeadm will output instructions to finish setting up <strong>kubectl</strong> on the master node and provide the join command for your worker nodes.</p>
<p><strong>Notes:</strong></p>
<ul>
<li>The <code>--pod-network-cidr</code> value must align with the configuration of the pod network solution (e.g., Calico, Flannel) you plan to deploy.</li>
<li>Make sure that the control plane endpoint (<code>k8s-master.local</code>) is properly configured in your DNS or <code>/etc/hosts</code> file so that all nodes can resolve it.</li>
</ul>
<p>At this point, the control plane will be ready, and the next step will be to install a network add-on to allow pod-to-pod communication within the cluster.</p>
<p><strong>Output</strong>:</p>
<pre tabindex="0"><code>azureuser@k8s-master:~$ sudo kubeadm init \
  --pod-network-cidr=10.10.0.0/16 \
  --control-plane-endpoint=k8s-master.local
[init] Using Kubernetes version: v1.26.1
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using &#39;kubeadm config images pull&#39;
[certs] Using certificateDir folder &#34;/etc/kubernetes/pki&#34;
[certs] Generating &#34;ca&#34; certificate and key
[certs] Generating &#34;apiserver&#34; certificate and key
[certs] apiserver serving cert is signed for DNS names [k8s-master.local kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.1.10]
[certs] Generating &#34;apiserver-kubelet-client&#34; certificate and key
[certs] Generating &#34;front-proxy-ca&#34; certificate and key
[certs] Generating &#34;front-proxy-client&#34; certificate and key
[certs] Generating &#34;etcd/ca&#34; certificate and key
[certs] Generating &#34;etcd/server&#34; certificate and key
[certs] etcd/server serving cert is signed for DNS names [k8s-master.local localhost] and IPs [192.168.1.10 127.0.0.1 ::1]
[certs] Generating &#34;etcd/peer&#34; certificate and key
[certs] etcd/peer serving cert is signed for DNS names [k8s-master.local localhost] and IPs [192.168.1.10 127.0.0.1 ::1]
[certs] Generating &#34;etcd/healthcheck-client&#34; certificate and key
[certs] Generating &#34;apiserver-etcd-client&#34; certificate and key
[certs] Generating &#34;sa&#34; key and public key
[kubeconfig] Using kubeconfig folder &#34;/etc/kubernetes&#34;
[kubeconfig] Writing &#34;admin.conf&#34; kubeconfig file
[kubeconfig] Writing &#34;kubelet.conf&#34; kubeconfig file
[kubeconfig] Writing &#34;controller-manager.conf&#34; kubeconfig file
[kubeconfig] Writing &#34;scheduler.conf&#34; kubeconfig file
[kubelet-start] Writing kubelet environment file with flags to file &#34;/var/lib/kubelet/kubeadm-flags.env&#34;
[kubelet-start] Writing kubelet configuration to file &#34;/var/lib/kubelet/config.yaml&#34;
[kubelet-start] Starting the kubelet
[control-plane] Using manifest folder &#34;/etc/kubernetes/manifests&#34;
[control-plane] Creating static Pod manifest for &#34;kube-apiserver&#34;
[control-plane] Creating static Pod manifest for &#34;kube-controller-manager&#34;
[control-plane] Creating static Pod manifest for &#34;kube-scheduler&#34;
[etcd] Creating static Pod manifest for local etcd in &#34;/etc/kubernetes/manifests&#34;
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &#34;/etc/kubernetes/manifests&#34;. This can take up to 4m0s
[apiclient] All control plane components are healthy after 7.503422 seconds
[upload-config] Storing the configuration used in ConfigMap &#34;kubeadm-config&#34; in the &#34;kube-system&#34; Namespace
[kubelet] Creating a ConfigMap &#34;kubelet-config&#34; in namespace kube-system with the configuration for the kubelets in the cluster
[upload-certs] Skipping phase. Please see --upload-certs
[mark-control-plane] Marking the node k8s-master.local as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
[mark-control-plane] Marking the node k8s-master.local as control-plane by adding the taints [node-role.kubernetes.io/control-plane:NoSchedule]
[bootstrap-token] Using token: daii9y.g4dq24u6irkz4pt0
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap,RBAC Roles
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstrap-token] Creating the &#34;cluster-info&#34; ConfigMap in the &#34;kube-public&#34; namespace
[kubelet-finalize] Updating &#34;/etc/kubernetes/kubelet.conf&#34; to point to a rotatable kubelet client certificate and key
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regularuser:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config==

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run &#34;kubectl apply -f [podnetwork].yaml&#34; with one of the options listedat:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of control-plane nodes by copying certificate authorities
and service account keys on each node and then running the following asroot:

  kubeadm join k8s-master.local:6443 --token daii9y.g4dq24u6irkz4pt0 \
        --discovery-token-ca-cert-hash sha256:58b9cc96ed57a5797fddea653756dbda830efbff55b720a10cffb3948d489148 \
        --control-plane

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join k8s-master.local:6443 --token daii9y.g4dq24u6irkz4pt0 \
        --discovery-token-ca-cert-hash sha256:58b9cc96ed57a5797fddea653756dbda830efbff55b720a10cffb3948d489148
</code></pre><blockquote>
<p>ℹ️ Now, As shown in the output execute below command in master node.</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir -p <span style="color:#79c0ff">$HOME</span>/.kube
</span></span><span style="display:flex;"><span>sudo cp -i /etc/kubernetes/admin.conf <span style="color:#79c0ff">$HOME</span>/.kube/config
</span></span><span style="display:flex;"><span>sudo chown <span style="color:#ff7b72">$(</span>id -u<span style="color:#ff7b72">)</span>:<span style="color:#ff7b72">$(</span>id -g<span style="color:#ff7b72">)</span> <span style="color:#79c0ff">$HOME</span>/.kube/config
</span></span></code></pre></div><p>Verify the cluster status:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl cluster-info
</span></span><span style="display:flex;"><span>kubectl get nodes
</span></span></code></pre></div><p><strong>Output</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>azureuser@k8s-master:~$ kubectl cluster-info
</span></span><span style="display:flex;"><span>Kubernetes control plane is running at https://k8s-master.local:6443
</span></span><span style="display:flex;"><span>CoreDNS is running at https://k8s-master.local:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>To further debug and diagnose cluster problems, use <span style="color:#a5d6ff">&#39;kubectl cluster-info dump&#39;</span>.
</span></span><span style="display:flex;"><span>azureuser@k8s-master:~$ kubectl get nodes
</span></span><span style="display:flex;"><span>NAME                    STATUS   ROLES           AGE    VERSION
</span></span><span style="display:flex;"><span>k8s-master.local        Ready    control-plane   3d3h   v1.30.4
</span></span></code></pre></div><p>It seems the control plane is running, we will proceed to add worker nodes to this cluster.</p>
<hr>
<h1 id="adding-worker-nodes-to-the-kubernetes-cluster">Adding Worker Nodes to the Kubernetes Cluster</h1>
<p>After initializing the Kubernetes cluster on the master node, it&rsquo;s time to add your worker nodes to the cluster. This will allow the control plane to distribute workloads across the nodes and manage them.</p>
<blockquote>
<p>ℹ️ To add a worker node, you need to execute the kubeadm join command in worker nodes.</p>
</blockquote>
<p>This command securely connects the worker node to the control plane. the command typically looks something like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubeadm join k8s-master.local:6443 --token daii9y.g4dq24u6irkz4pt0 <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>  --discovery-token-ca-cert-hash sha256:58b9cc96ed57a5797fddea653756dbda830efbff55b720a10cffb3948d489148
</span></span></code></pre></div><ul>
<li><strong>k8s-master.local:6443</strong>: This is the control plane endpoint (master node&rsquo;s address).</li>
<li><strong>&ndash;token</strong>: The token generated during the kubeadm init process, which allows the worker node to authenticate with the control plane.</li>
<li><strong>&ndash;discovery-token-ca-cert-hash</strong>: A hash that ensures the worker node securely discovers the control plane’s certificate authority.</li>
</ul>
<p>Once this command completes successfully, the worker node will be part of the Kubernetes cluster, ready to run workloads distributed by the control plane. You can verify that the node has joined the cluster by running the following command on the master node:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get nodes
</span></span></code></pre></div><p><strong>Output</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>azureuser@k8s-master:~$ kubectl get nodes
</span></span><span style="display:flex;"><span>NAME                    STATUS   ROLES           AGE    VERSION
</span></span><span style="display:flex;"><span>k8s-master.local        Ready    control-plane   3d3h   v1.30.4
</span></span><span style="display:flex;"><span>k8s-worker1.local       Ready    &lt;none&gt;          3d3h   v1.30.4
</span></span></code></pre></div><p>This will list all nodes, including the newly added workers, along with their status in the cluster.</p>
<p>Repeat the process for each worker node to ensure that all machines are part of the cluster.</p>
<hr>
<p>Here’s the updated blog paragraph with the <code>sed</code> command for editing the Calico manifest:</p>
<hr>
<h1 id="installing-calico-v3281-pod-network-for-the-kubernetes-cluster">Installing Calico (v3.28.1) Pod Network for the Kubernetes Cluster</h1>
<p>In order to allow communication between the pods in your cluster, you&rsquo;ll need to install a network add-on. One of the most popular options is <strong>Calico</strong>, which provides networking and network security capabilities for Kubernetes. Below, we&rsquo;ll walk through how to install <strong>Calico</strong> on your Kubernetes cluster.</p>
<blockquote>
<p>ℹ️ These commands should be run only on the <strong>master node</strong>.</p>
</blockquote>
<h2 id="1-download-the-calico-manifest-file">1. Download the Calico Manifest File</h2>
<p>To begin, download the Calico manifest file, which is pre-configured for clusters with fewer than 50 nodes:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl https://raw.githubusercontent.com/projectcalico/calico/v3.28.1/manifests/calico.yaml -O
</span></span></code></pre></div><p>This file contains all the necessary configuration to deploy Calico on your Kubernetes cluster.</p>
<h2 id="2-edit-the-calico-manifest-using-sed">2. Edit the Calico Manifest Using <code>sed</code></h2>
<p>To streamline the process of modifying the <strong>CALICO_IPV4POOL_CIDR</strong> in the <strong>calico.yaml</strong> file, you can use the following <code>sed</code> command. This automatically updates the pod network CIDR without manually opening the file:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sed -i <span style="color:#a5d6ff">&#39;s/value: &#34;192.168.0.0\/16&#34;/value: &#34;10.10.0.0\/16&#34;/&#39;</span> calico.yaml
</span></span></code></pre></div><p>This command ensures that the pod network CIDR matches the one you specified during cluster initialization (<code>10.10.0.0/16</code>).</p>
<h2 id="3-apply-the-calico-manifest">3. Apply the Calico Manifest</h2>
<p>Once the manifest is updated, install Calico by applying the configuration using <strong>kubectl</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f calico.yaml
</span></span></code></pre></div><p>Calico will be deployed on your cluster, enabling pod-to-pod communication and enforcing network policies.</p>
<p><strong>Output</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>azureuser@k8s-master:~$ kubectl apply -f calico.yaml
</span></span><span style="display:flex;"><span>poddisruptionbudget.policy/calico-kube-controllers created
</span></span><span style="display:flex;"><span>serviceaccount/calico-kube-controllers created
</span></span><span style="display:flex;"><span>serviceaccount/calico-node created
</span></span><span style="display:flex;"><span>configmap/calico-config created
</span></span><span style="display:flex;"><span>customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created
</span></span><span style="display:flex;"><span>customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created
</span></span><span style="display:flex;"><span>customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created
</span></span><span style="display:flex;"><span>customresourcedefinition.apiextensions.k8s.io/caliconodestatuses.crd.projectcalico.org created
</span></span><span style="display:flex;"><span>customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created
</span></span><span style="display:flex;"><span>customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created
</span></span><span style="display:flex;"><span>customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created
</span></span><span style="display:flex;"><span>customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created
</span></span><span style="display:flex;"><span>customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created
</span></span><span style="display:flex;"><span>customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created
</span></span><span style="display:flex;"><span>customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created
</span></span><span style="display:flex;"><span>customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created
</span></span><span style="display:flex;"><span>customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created
</span></span><span style="display:flex;"><span>customresourcedefinition.apiextensions.k8s.io/ipreservations.crd.projectcalico.org created
</span></span><span style="display:flex;"><span>customresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org created
</span></span><span style="display:flex;"><span>customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created
</span></span><span style="display:flex;"><span>customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created
</span></span><span style="display:flex;"><span>clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created
</span></span><span style="display:flex;"><span>clusterrole.rbac.authorization.k8s.io/calico-node created
</span></span><span style="display:flex;"><span>clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created
</span></span><span style="display:flex;"><span>clusterrolebinding.rbac.authorization.k8s.io/calico-node created
</span></span><span style="display:flex;"><span>daemonset.apps/calico-node created
</span></span><span style="display:flex;"><span>deployment.apps/calico-kube-controllers created
</span></span></code></pre></div><h1 id="verifying-the-k8s-installation">Verifying the K8s Installation</h1>
<p>You can verify that Calico is running correctly by checking the status of the pods in the <code>kube-system</code> namespace:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get pods -n kube-system
</span></span></code></pre></div><p><strong>Output</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>azureuser@k8s-master:~$ kubectl get pods -n kube-system
</span></span><span style="display:flex;"><span>NAME                                           READY   STATUS    RESTARTS        AGE
</span></span><span style="display:flex;"><span>calico-kube-controllers-77d59654f4-25crd       1/1     Running   <span style="color:#a5d6ff">5</span> <span style="color:#ff7b72;font-weight:bold">(</span>3h59m ago<span style="color:#ff7b72;font-weight:bold">)</span>   3d3h
</span></span><span style="display:flex;"><span>calico-node-hqf82                              1/1     Running   <span style="color:#a5d6ff">2</span> <span style="color:#ff7b72;font-weight:bold">(</span>3h59m ago<span style="color:#ff7b72;font-weight:bold">)</span>   3d3h
</span></span><span style="display:flex;"><span>calico-node-jxwbm                              1/1     Running   <span style="color:#a5d6ff">4</span> <span style="color:#ff7b72;font-weight:bold">(</span>3h55m ago<span style="color:#ff7b72;font-weight:bold">)</span>   3d3h
</span></span><span style="display:flex;"><span>coredns-7db6d8ff4d-6f9cn                       1/1     Running   <span style="color:#a5d6ff">2</span> <span style="color:#ff7b72;font-weight:bold">(</span>3h59m ago<span style="color:#ff7b72;font-weight:bold">)</span>   3d4h
</span></span><span style="display:flex;"><span>coredns-7db6d8ff4d-dnzq2                       1/1     Running   <span style="color:#a5d6ff">2</span> <span style="color:#ff7b72;font-weight:bold">(</span>3h59m ago<span style="color:#ff7b72;font-weight:bold">)</span>   3d4h
</span></span></code></pre></div><p>You should see Calico components such as <code>calico-node</code> and <code>calico-kube-controllers</code> running successfully.</p>
<p>With Calico installed, your Kubernetes cluster is now fully networked, allowing pods to communicate across nodes as necessary. You can also configure Calico for advanced network security features if needed.</p>
<p>Now if we check the status of the nodes, the status will be Ready.</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get nodes
</span></span></code></pre></div><p><strong>Output</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>azureuser@k8s-master:~$ kubectl get nodes
</span></span><span style="display:flex;"><span>NAME                    STATUS   ROLES           AGE    VERSION
</span></span><span style="display:flex;"><span>k8s-master.local    Ready    control-plane   3d4h   v1.30.4
</span></span><span style="display:flex;"><span>k8s-worker1.local   Ready    &lt;none&gt;          3d4h   v1.30.4
</span></span></code></pre></div><hr>
<p>Congrats, if you reach till the end 😊. You are a soldier 🪖.</p>

                    
                    <HR width="100%" id="EOF">
		    <p style="color:#777;">Last modified on 2024-09-06</p>
                    
                </div>
            </div>
            
            
            <nav class="post-pagination">

                
                <a class="newer-posts" href="/posts/installing-kafka-and-kafka-connect-on-seperate-servers/">
			Next<br>Installing Kafka and Kafka Connect on Seperate Servers
                </a>
                
                
                
                <a class="older-posts" href="/posts/port-not-available/">
			Previous<br>Port Not Available: 503 Server Unavailable
                </a>
                
            </nav>
            <div class="post-comment-wrapper">
                












            </div>
        </div>
    </div>


                    </div>
            </div><div id="sideContainer" class="side-container">
    
    <a class="a-block nav-head false" href="https://bookofdaniel.in/">
    
        <div class="nav-title">
            Book Of Daniel
        </div>
        
    </a>

    <div class="nav-link-list">
        
        
            
            
            
                
            
            
            
            <a class="a-block nav-link-item active" href="/posts">
                Archives
            </a>
            
        
    </div>

    

    <div class="nav-footer">
        
&copy;
	
	2024
	

    </div>
    
</div><div id="extraContainer" class="extra-container">
    <div class="toc-wrapper">
        

        
        <div class="toc">


	<div class="toc-content">
	
		
		
		
		<center>- CATALOG -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#requirements" class="nav-requirements">
									Requirements
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#provisioning-the-servers-in-azure" class="nav-provisioning-the-servers-in-azure">
									Provisioning the Servers in Azure
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#system-preparation-for-kubernetes-installation" class="nav-system-preparation-for-kubernetes-installation">
									System Preparation for Kubernetes Installation
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#1-update-the-os" class="nav-1-update-the-os">
									1. Update the OS
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#2-set-hostname" class="nav-2-set-hostname">
									2. Set Hostname
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#3-disable-swap" class="nav-3-disable-swap">
									3. Disable Swap
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#4-update-kernel-and-configure-modules" class="nav-4-update-kernel-and-configure-modules">
									4. Update Kernel and Configure Modules
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#installing-containerd-runtime-on-all-nodes" class="nav-installing-containerd-runtime-on-all-nodes">
									Installing Containerd Runtime on All Nodes
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#installing-kubeadm-kubelet-and-kubectl" class="nav-installing-kubeadm-kubelet-and-kubectl">
									Installing Kubeadm, Kubelet, and Kubectl
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#1-update-package-index-and-install-dependencies" class="nav-1-update-package-index-and-install-dependencies">
									1. Update Package Index and Install Dependencies
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#2-add-the-kubernetes-signing-key" class="nav-2-add-the-kubernetes-signing-key">
									2. Add the Kubernetes Signing Key
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#3-add-the-kubernetes-v131-repository" class="nav-3-add-the-kubernetes-v131-repository">
									3. Add the Kubernetes v1.31 Repository
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#4-install-kubelet-kubeadm-and-kubectl" class="nav-4-install-kubelet-kubeadm-and-kubectl">
									4. Install Kubelet, Kubeadm, and Kubectl
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#5-enable-the-kubelet-service-optional" class="nav-5-enable-the-kubelet-service-optional">
									5. Enable the Kubelet Service (Optional)
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#initializing-the-kubernetes-cluster-with-kubeadm" class="nav-initializing-the-kubernetes-cluster-with-kubeadm">
									Initializing the Kubernetes Cluster with Kubeadm
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#adding-worker-nodes-to-the-kubernetes-cluster" class="nav-adding-worker-nodes-to-the-kubernetes-cluster">
									Adding Worker Nodes to the Kubernetes Cluster
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#installing-calico-v3281-pod-network-for-the-kubernetes-cluster" class="nav-installing-calico-v3281-pod-network-for-the-kubernetes-cluster">
									Installing Calico (v3.28.1) Pod Network for the Kubernetes Cluster
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#1-download-the-calico-manifest-file" class="nav-1-download-the-calico-manifest-file">
									1. Download the Calico Manifest File
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#2-edit-the-calico-manifest-using-sed" class="nav-2-edit-the-calico-manifest-using-sed">
									2. Edit the Calico Manifest Using sed
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#3-apply-the-calico-manifest" class="nav-3-apply-the-calico-manifest">
									3. Apply the Calico Manifest
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#verifying-the-k8s-installation" class="nav-verifying-the-k8s-installation">
									Verifying the K8s Installation
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
        
    </div>
    <div class="pagination">
        <a id="globalBackToTop" class="pagination-action animated-visibility" href="#top"
            :class="{ invisible: scrollY == 0 }">
            <i class="material-icons pagination-action-icon">
                keyboard_arrow_up
            </i>
        </a>
        
        <a type="button" class="pagination-action" id="darkModeToggleButton">
            <span class="material-icons pagination-action-icon" id="darkModeToggleIcon">
                dark_mode
            </span>
        </a>
        
        
    </div>
</div>

<div id="single-column-footer">
&copy;
	
	2024
	
</div>
            </div>
    
    <script src="/js/journal.js"></script></body>
</html>
